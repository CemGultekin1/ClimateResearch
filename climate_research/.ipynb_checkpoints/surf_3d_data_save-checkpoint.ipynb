{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "704d934c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import argparse\n",
    "import intake\n",
    "from intake import open_catalog\n",
    "from matplotlib import colors, cm, pyplot as plt\n",
    "def advections(u_v_field: xr.Dataset, grid_data: xr.Dataset,typenum=0):\n",
    "    dxu = grid_data['dxu']\n",
    "    dyu = grid_data['dyu']\n",
    "    gradient_x = u_v_field.diff(dim='xu_ocean') / dxu\n",
    "    gradient_y = u_v_field.diff(dim='yu_ocean') / dyu\n",
    "    # Interpolate back the gradients\n",
    "    interp_coords = dict(xu_ocean=u_v_field.coords['xu_ocean'],\n",
    "                         yu_ocean=u_v_field.coords['yu_ocean'])\n",
    "    gradient_x = gradient_x.interp(interp_coords)\n",
    "    gradient_y = gradient_y.interp(interp_coords)\n",
    "    u, v = u_v_field['usurf'], u_v_field['vsurf']\n",
    "    \n",
    "    adv = u * gradient_x + v * gradient_y\n",
    "    names=list(u_v_field.keys())\n",
    "    \n",
    "    adv_u = u * gradient_x['usurf'] + v * gradient_y['usurf']\n",
    "    adv_v = u * gradient_x['vsurf'] + v * gradient_y['vsurf']\n",
    "    adv_T = u * gradient_x['surface_temp'] + v * gradient_y['surface_temp']\n",
    "    result = xr.Dataset({'Su': adv_u,'Sv': adv_v,'ST': adv_T })\n",
    "    \n",
    "    return result\n",
    "def spatial_filter(data: np.ndarray, sigma: float):\n",
    "    \n",
    "    ndim=len(data.shape)\n",
    "    #print(ndim)\n",
    "    if ndim==3:\n",
    "        result = np.zeros_like(data)\n",
    "        for t in range(data.shape[0]):\n",
    "            data_t = data[t, ...]\n",
    "            result_t = gaussian_filter(data_t, sigma, mode='constant')\n",
    "            result[t, ...] = result_t\n",
    "    elif ndim==4:\n",
    "        preshape=data.shape\n",
    "        data=data.reshape([preshape[0]*preshape[1],preshape[2],preshape[3]])\n",
    "        result = np.zeros(data.shape)\n",
    "        for t in range(data.shape[0]):\n",
    "            data_t = data[t, ...]\n",
    "            result_t = gaussian_filter(data_t, sigma, mode='constant')\n",
    "            result[t, ...] = result_t\n",
    "        result=result.reshape([preshape[0],preshape[1],result.shape[1],result.shape[2]])\n",
    "    return result\n",
    "\n",
    "def spatial_filter_dataset(dataset: xr.Dataset, grid_info: xr.Dataset,\n",
    "                           sigma: float):\n",
    "    area_u = grid_info['dxu'] * grid_info['dyu'] / 1e8\n",
    "    dataset = dataset * area_u\n",
    "    # Normalisation term, so that if the quantity we filter is constant\n",
    "    # over the domain, the filtered quantity is constant with the same value\n",
    "    norm = xr.apply_ufunc(lambda x: gaussian_filter(x, sigma, mode='constant'),\n",
    "                          area_u, dask='parallelized', output_dtypes=[float, ])\n",
    "    filtered = xr.apply_ufunc(lambda x: spatial_filter(x, sigma), dataset,\n",
    "                              dask='parallelized', output_dtypes=[float, ])\n",
    "    return filtered / norm\n",
    "\n",
    "def eddy_forcing(u_v_dataset : xr.Dataset, grid_data: xr.Dataset,\n",
    "                 scale: int, method: str = 'mean',\n",
    "                 nan_or_zero: str = 'zero', scale_mode: str = 'factor',\n",
    "                 debug_mode=False,typenum=0) -> xr.Dataset:\n",
    "\n",
    "    # Replace nan values with zeros.\n",
    "    if nan_or_zero == 'zero':\n",
    "        u_v_dataset = u_v_dataset.fillna(0.0)\n",
    "    if scale_mode == 'factor':\n",
    "        #print('Using factor mode')\n",
    "        scale_x = scale\n",
    "        scale_y = scale\n",
    "\n",
    "    scale_filter = (scale_x / 2, scale_y / 2)\n",
    "    # High res advection terms\n",
    "    adv = advections(u_v_dataset, grid_data,typenum=typenum)\n",
    "    # Filtered advections\n",
    "    filtered_adv = spatial_filter_dataset(adv, grid_data, scale_filter)\n",
    "    # Filtered u,v field and temperature\n",
    "    u_v_filtered = spatial_filter_dataset(u_v_dataset, grid_data, scale_filter)\n",
    "    # Advection term from filtered velocity field\n",
    "    adv_filtered = advections(u_v_filtered, grid_data,typenum=typenum)\n",
    "    # Forcing\n",
    "    forcing = adv_filtered - filtered_adv\n",
    "    #if typenum==0:\n",
    "    #forcing = forcing.rename({'adv': 'S'})\n",
    "    # Merge filtered u,v, temperature and forcing terms\n",
    "    forcing = forcing.merge(u_v_filtered)\n",
    "    # Coarsen\n",
    "    #print('scale factor: ', scale)\n",
    "    forcing_coarse = forcing.coarsen({'xu_ocean': int(scale_x),\n",
    "                                      'yu_ocean': int(scale_y)},\n",
    "                                     boundary='trim')\n",
    "    if method == 'mean':\n",
    "        forcing_coarse = forcing_coarse.mean()\n",
    "    else:\n",
    "        raise ValueError('Passed coarse-graining method not implemented.')\n",
    "    if nan_or_zero == 'zero':\n",
    "        # Replace zeros with nans for consistency\n",
    "        forcing_coarse = forcing_coarse.where(forcing_coarse['usurf'] != 0)\n",
    "    if not debug_mode:\n",
    "        return forcing_coarse\n",
    "    u_v_dataset = u_v_dataset.merge(adv)\n",
    "    filtered_adv = filtered_adv.rename({'adv_x': 'f_adv_x',\n",
    "                                        'adv_y': 'f_adv_y'})\n",
    "    adv_filtered = adv_filtered.rename({'adv_x': 'adv_f_x',\n",
    "                                        'adv_y': 'adv_f_y'})\n",
    "    u_v_filtered = u_v_filtered.rename({'usurf': 'f_usurf',\n",
    "                                        'vsurf': 'f_vsurf'})\n",
    "    u_v_dataset = xr.merge((u_v_dataset, u_v_filtered, adv, filtered_adv,\n",
    "                            adv_filtered, forcing[['S_x', 'S_y']]))\n",
    "    return u_v_dataset, forcing_coarse\n",
    "\n",
    "def coarsen_save(sigma,typenum,testflag=False,projection=False,rewrite=False):\n",
    "    if typenum==0:\n",
    "        raw_data_address='/scratch/zanna/data/cm2.6/surf-data.zarr'\n",
    "        u_v_dataset=xr.open_zarr(raw_data_address).chunk(chunks={\"time\":1})\n",
    "        if not testflag:\n",
    "            filename='/scratch/zanna/data/cm2.6/coarse-surf-data-sigma-'+str(sigma)+'.zarr'\n",
    "        else:\n",
    "            filename='/scratch/zanna/data/cm2.6/coarse-surf-data-sigma-'+str(sigma)+'-test.zarr'\n",
    "        if projection:\n",
    "            QQx,QQy,_,_=compute_projections(sigma,stratind=0)\n",
    "    elif typenum==1:\n",
    "        raw_data_address='/scratch/zanna/data/cm2.6/3D-data.zarr'\n",
    "        #stratinds=np.array([0,10,20,30])\n",
    "        stratinds=np.array([0,5,10,15,20,30,40])\n",
    "        #stratinds=10#np.array([10])\n",
    "        u_v_dataset=xr.open_zarr(raw_data_address)\\\n",
    "                        .chunk(chunks={\"time\":1})\\\n",
    "                        .isel(st_ocean=stratinds)\\\n",
    "                        .drop(\"salt nv st_edges_ocean xt_ocean yt_ocean\".split())\\\n",
    "                        .rename({\"u\":\"usurf\",\"v\":\"vsurf\",\"temp\":\"surface_temp\"})\n",
    "        stratvals=u_v_dataset.st_ocean.values#np.concatenate([[0],u_v_dataset.st_ocean.values],axis=(0))\n",
    "        if not testflag:\n",
    "            filename='/scratch/zanna/data/cm2.6/coarse-3D-data-sigma-'+str(sigma)+'.zarr'\n",
    "        else:\n",
    "            filename='/scratch/zanna/data/cm2.6/coarse-3D-data-sigma-'+str(sigma)+'-test.zarr'\n",
    "        if projection:\n",
    "            QQx,QQy,_,_=compute_projections(sigma,stratind=1)\n",
    "    elif typenum==2:\n",
    "        raw_data_address='/scratch/zanna/data/cm2.6/1pct-CO2-surf-data.zarr'\n",
    "        u_v_dataset=xr.open_zarr(raw_data_address)\\\n",
    "                        .chunk(chunks={\"time\":1})\n",
    "        if not testflag:\n",
    "            filename='/scratch/zanna/data/cm2.6/coarse-1pct-CO2-surf-data-sigma-'+str(sigma)+'.zarr'\n",
    "        else:\n",
    "            filename='/scratch/zanna/data/cm2.6/coarse-1pct-CO2-surf-data-sigma-'+str(sigma)+'-test.zarr'\n",
    "        if projection:\n",
    "            QQx,QQy,_,_=compute_projections(sigma,raw_data_address=raw_data_address)\n",
    "    elif typenum==3:\n",
    "        raw_data_address='/scratch/zanna/data/cm2.6/1pct-CO2-3D-data.zarr'\n",
    "        stratinds=np.array([0,5,10,15,20,30,40])\n",
    "        u_v_dataset=xr.open_zarr(raw_data_address)\\\n",
    "                        .chunk(chunks={\"time\":1})\\\n",
    "                        .isel(st_ocean=stratinds)\\\n",
    "                        .drop(\"nv st_edges_ocean xt_ocean yt_ocean\".split())\\\n",
    "                        .rename({\"u\":\"usurf\",\"v\":\"vsurf\",\"temp\":\"surface_temp\"})\n",
    "        stratvals=u_v_dataset.st_ocean.values\n",
    "        if not testflag:\n",
    "            filename='/scratch/zanna/data/cm2.6/coarse-1pct-CO2-3D-data-sigma-'+str(sigma)+'.zarr'\n",
    "        else:\n",
    "            filename='/scratch/zanna/data/cm2.6/coarse-1pct-CO2-3D-data-sigma-'+str(sigma)+'-test.zarr'\n",
    "        if projection:\n",
    "            QQx,QQy,_,_=compute_projections(sigma,stratind=1,raw_data_address=raw_data_address)\n",
    "    if testflag:\n",
    "        print('running test')\n",
    "        u_v_dataset=u_v_dataset.isel(time=np.arange(4))\n",
    "    nb=sigma*4\n",
    "\n",
    "    x=u_v_dataset.xu_ocean.values\n",
    "    y=u_v_dataset.yu_ocean.values\n",
    "    dx=x[1]-x[0]\n",
    "    xbeg=x[0]\n",
    "    xter=x[-1]\n",
    "    x=np.concatenate([dx*np.arange(-nb,0)+xbeg,x,dx*np.arange(1,nb+1)+xter],axis=0)\n",
    "    dx=x[1:]-x[:-1]\n",
    "    dy=y[1:]-y[:-1]\n",
    "\n",
    "    dx=np.reshape(dx,(1,-1))\n",
    "    dx=[dx for i in range(len(y)-1)]\n",
    "    dx=np.concatenate(dx,axis=0)\n",
    "    #dx=np.stack([dx],axis=0)\n",
    "\n",
    "    dy=np.reshape(dy,(-1,1))\n",
    "    dy=[dy for i in range(len(x)-1)]\n",
    "    dy=np.concatenate(dy,axis=1)\n",
    "    grid_data=xr.Dataset(data_vars=dict(dxu=([\"yu_ocean\",\"xu_ocean\"],dx),\\\n",
    "                                        dyu=([\"yu_ocean\",\"xu_ocean\"],dy)),\\\n",
    "                            coords=dict(xu_ocean=x[:-1],yu_ocean=y[:-1]))\n",
    "    print('saving '+str(sigma)+'...',flush=True)\n",
    "    print(filename)\n",
    "    tmax=len(u_v_dataset.time)\n",
    "    try:\n",
    "        ds=xr.open_zarr(filename)\n",
    "        tmin=ds.time.values[-1]\n",
    "    except:\n",
    "        tmin=0\n",
    "    if testflag:\n",
    "        tmin=0\n",
    "    if rewrite:\n",
    "        tmin=0\n",
    "    print(\"tmin: \"+str(tmin)+\",  tmax: \"+str(tmax))\n",
    "    time_chunk=sigma\n",
    "    print(\"time_chunksize: \"+str(time_chunk))\n",
    "\n",
    "    no_depth=typenum%2==0\n",
    "    for j in range(tmin//time_chunk,tmax//time_chunk):\n",
    "        ter=min(tmax,(j+1)*time_chunk)\n",
    "        print('\\t\\t'+str(j*time_chunk)+' : '+ str(tmax),flush=True)\n",
    "        times_=np.arange(j*time_chunk,ter)\n",
    "        for times__ in times_:\n",
    "            times=np.arange(times__,times__+1)\n",
    "            u_v_datasetj=u_v_dataset.isel(time=times)\n",
    "            if no_depth:\n",
    "                u=np.stack([u_v_datasetj.usurf.values,\\\n",
    "                            u_v_datasetj.vsurf.values,\\\n",
    "                              u_v_datasetj.surface_temp.values],axis=0)\n",
    "            else:\n",
    "                u=np.concatenate([u_v_datasetj.usurf.values,\\\n",
    "                            u_v_datasetj.vsurf.values,\\\n",
    "                              u_v_datasetj.surface_temp.values],axis=0)\n",
    "            if projection:\n",
    "                uL=u*1\n",
    "                uH=u*1\n",
    "                for t in range(u.shape[0]*u.shape[1]):\n",
    "                    t1=t%u.shape[0]\n",
    "                    t2=t//u.shape[0]\n",
    "                    ut=u[t1,t2]*1\n",
    "                    mask=ut*1\n",
    "                    mask[mask==mask]=1\n",
    "                    ut[ut!=ut]=0\n",
    "                    u0=(QQx@(QQx.T@ut)@QQy)@QQy.T\n",
    "                    uL[t1,t2]=u0*mask\n",
    "                    uH[t1,t2]=(ut-u0)*mask\n",
    "                uL=np.concatenate([uL[:,:,:,-nb:],uL,uL[:,:,:,:nb]],axis=3)\n",
    "                uH=np.concatenate([uH[:,:,:,-nb:],uH,uH[:,:,:,:nb]],axis=3)\n",
    "            u=np.concatenate([u[:,:,:,-nb:],u,u[:,:,:,:nb]],axis=3)\n",
    "            if no_depth:\n",
    "                uv=xr.Dataset(data_vars=dict(usurf=([\"time\",\"yu_ocean\",\"xu_ocean\"],u[0]),\\\n",
    "                                                vsurf=([\"time\",\"yu_ocean\",\"xu_ocean\"],u[1]),\\\n",
    "                                                 surface_temp=([\"time\",\"yu_ocean\",\"xu_ocean\"],u[2])),\\\n",
    "                                    coords=dict(xu_ocean=x,yu_ocean=y,time=times))  \n",
    "                if projection:\n",
    "                    uvL=xr.Dataset(data_vars=dict(usurf=([\"time\",\"yu_ocean\",\"xu_ocean\"],uL[0]),\\\n",
    "                                            vsurf=([\"time\",\"yu_ocean\",\"xu_ocean\"],uL[1]),\\\n",
    "                                             surface_temp=([\"time\",\"yu_ocean\",\"xu_ocean\"],uL[2])),\\\n",
    "                                coords=dict(xu_ocean=x,yu_ocean=y,time=times))\n",
    "                    uvH=xr.Dataset(data_vars=dict(usurf=([\"time\",\"yu_ocean\",\"xu_ocean\"],uH[0]),\\\n",
    "                                            vsurf=([\"time\",\"yu_ocean\",\"xu_ocean\"],uH[1]),\\\n",
    "                                             surface_temp=([\"time\",\"yu_ocean\",\"xu_ocean\"],uH[2])),\\\n",
    "                                coords=dict(xu_ocean=x,yu_ocean=y,time=times))\n",
    "            else:\n",
    "                uv=xr.Dataset(data_vars=dict(usurf=([\"time\",\"st_ocean\",\"yu_ocean\",\"xu_ocean\"],u[0:1]),\\\n",
    "                                    vsurf=([\"time\",\"st_ocean\",\"yu_ocean\",\"xu_ocean\"],u[1:2]),\\\n",
    "                                     surface_temp=([\"time\",\"st_ocean\",\"yu_ocean\",\"xu_ocean\"],u[2:3])),\\\n",
    "                        coords=dict(st_ocean=stratvals,xu_ocean=x,yu_ocean=y,time=times))  \n",
    "                if projection:\n",
    "                    uvL=xr.Dataset(data_vars=dict(usurf=([\"time\",\"st_ocean\",\"yu_ocean\",\"xu_ocean\"],uL[0:1]),\\\n",
    "                                            vsurf=([\"time\",\"st_ocean\",\"yu_ocean\",\"xu_ocean\"],uL[1:2]),\\\n",
    "                                             surface_temp=([\"time\",\"st_ocean\",\"yu_ocean\",\"xu_ocean\"],uL[2:3])),\\\n",
    "                                coords=dict(st_ocean=stratvals,xu_ocean=x,yu_ocean=y,time=times))\n",
    "                    uvH=xr.Dataset(data_vars=dict(usurf=([\"time\",\"st_ocean\",\"yu_ocean\",\"xu_ocean\"],uH[0:1]),\\\n",
    "                                            vsurf=([\"time\",\"st_ocean\",\"yu_ocean\",\"xu_ocean\"],uH[1:2]),\\\n",
    "                                             surface_temp=([\"time\",\"st_ocean\",\"yu_ocean\",\"xu_ocean\"],uH[2:3])),\\\n",
    "                                coords=dict(st_ocean=stratvals,xu_ocean=x,yu_ocean=y,time=times))\n",
    "            forcing1=eddy_forcing(uv, grid_data,sigma,nan_or_zero='nan',typenum=typenum).sel(yu_ocean=slice(-85, 85))\\\n",
    "                .sel(xu_ocean=slice(xbeg,xter))\n",
    "            if projection:\n",
    "                forcingL=eddy_forcing(uvL, grid_data,sigma,nan_or_zero='nan',typenum=typenum).sel(yu_ocean=slice(-85, 85))\\\n",
    "                    .sel(xu_ocean=slice(xbeg,xter))\n",
    "                forcingH=eddy_forcing(uvH, grid_data,sigma,nan_or_zero='nan',typenum=typenum).sel(yu_ocean=slice(-85, 85))\\\n",
    "                    .sel(xu_ocean=slice(xbeg,xter))\n",
    "                nms=['Su','Sv','ST']\n",
    "                for nm in nms:\n",
    "                    forcingL[nm].values=forcing1[nm].values-forcingL[nm].values-forcingH[nm].values\n",
    "                    forcingH[nm].values=forcingL[nm].values+forcingH[nm].values\n",
    "                forcingL=forcingL.drop(\"usurf vsurf surface_temp\".split()).rename({'Su': 'Su_LH',\n",
    "                                                'Sv': 'Sv_LH','ST':'ST_LH'})\n",
    "                forcingH=forcingH.drop(\"usurf vsurf surface_temp\".split()).rename({'Su': 'Su_r',\n",
    "                                                'Sv': 'Sv_r','ST':'ST_r'})\n",
    "                forcing1=forcing1.merge(forcingL)\n",
    "                forcing1=forcing1.merge(forcingH)\n",
    "            if times__==times_[0]:\n",
    "                forcing=forcing1.copy(deep=True)\n",
    "            else:\n",
    "                forcing=forcing.merge(forcing1)\n",
    "            print('\\t\\t\\t\\t'+str((times__+1)/len(times_)),flush=True)\n",
    "        forcing=forcing.chunk(chunks={\"time\":len(forcing.time),\"xu_ocean\":len(forcing.xu_ocean),\"yu_ocean\":len(forcing.yu_ocean)})\n",
    "        if j==0:\n",
    "            forcing.to_zarr(filename,mode='w')\n",
    "        else:\n",
    "            forcing.to_zarr(filename,append_dim=\"time\",mode='a')\n",
    "    print('\\t\\t '+str(sigma)+' is done',flush=True)\n",
    "def compute_projections(sigma,stratind=-1,raw_data_address='/scratch/zanna/data/cm2.6/3D-data.zarr'):\n",
    "    u_v_dataset=xr.open_zarr(raw_data_address)\n",
    "    u_v_dataset=u_v_dataset.isel(time=np.arange(1)).drop(\"time\".split())\n",
    "    if stratind>=0:\n",
    "        u_v_dataset=u_v_dataset.isel(st_ocean=stratind)\\\n",
    "                    .drop(\"nv st_edges_ocean xt_ocean yt_ocean st_ocean\".split())\n",
    "        u_v_dataset=u_v_dataset['u'.split()]\n",
    "    else:\n",
    "        u_v_dataset=u_v_dataset.rename({'usurf':'u','vsurf':'v','surface_temp':'temp'})\n",
    "    nb=sigma*4\n",
    "    scale_x,scale_y=sigma,sigma\n",
    "    scale_filter = (scale_x / 2, scale_y / 2)\n",
    "\n",
    "    x=u_v_dataset.xu_ocean.values\n",
    "    y=u_v_dataset.yu_ocean.values\n",
    "    dx=x[1]-x[0]\n",
    "    xbeg=x[0]\n",
    "    xter=x[-1]\n",
    "    x=np.concatenate([dx*np.arange(-nb,0)+xbeg,x,dx*np.arange(1,nb)+xter],axis=0)\n",
    "    y=u_v_dataset.yu_ocean.values\n",
    "    dx=x[1:]-x[:-1]\n",
    "    dy=y[1:]-y[:-1]\n",
    "    dy=np.concatenate([dy,dy[-1:]])\n",
    "    dx=np.concatenate([dx,dx[-1:]])\n",
    "\n",
    "    dx=np.reshape(dx,(1,-1))\n",
    "    dx=[dx for i in range(len(y))]\n",
    "    dx=np.concatenate(dx,axis=0)\n",
    "\n",
    "    dy=np.reshape(dy,(-1,1))\n",
    "    dy=[dy for i in range(len(x))]\n",
    "    dy=np.concatenate(dy,axis=1)\n",
    "\n",
    "    grid_data=xr.Dataset(data_vars=dict(dxu=([\"yu_ocean\",\"xu_ocean\"],dx),\\\n",
    "                                        dyu=([\"yu_ocean\",\"xu_ocean\"],dy)),\\\n",
    "                            coords=dict(xu_ocean=x,yu_ocean=y))\n",
    "\n",
    "\n",
    "    x=u_v_dataset.xu_ocean.values.reshape([-1])\n",
    "    y=u_v_dataset.yu_ocean.values.reshape([-1])\n",
    "    dx=x[1]-x[0]\n",
    "    xbeg=x[0]\n",
    "    xter=x[-1]\n",
    "    x=np.concatenate([dx*np.arange(-nb,0)+xbeg,x,dx*np.arange(1,nb)+xter],axis=0)\n",
    "    dx=x[1:]-x[:-1]\n",
    "    dy=y[1:]-y[:-1]\n",
    "    dy=np.concatenate([dy,dy[-1:]])\n",
    "    dx=np.concatenate([dx,dx[-1:]])\n",
    "\n",
    "    \n",
    "    ny=u_v_dataset.u.shape[-2]\n",
    "    area_u=dy\n",
    "    norm=gaussian_filter(area_u, scale_filter[0], mode='constant').reshape([-1])\n",
    "    for i in range(ny):\n",
    "        uy=np.zeros(ny)\n",
    "        uy[i]=1\n",
    "        filtered=gaussian_filter(uy, sigma/2, mode='constant').reshape([-1])/norm\n",
    "        temp=xr.Dataset(data_vars=dict(u=([\"x\"],filtered)),\\\n",
    "                            coords=dict(x=np.arange(filtered.shape[0]))).coarsen({'x': sigma},\n",
    "             boundary='trim').mean()\n",
    "        cuy=temp.u.values\n",
    "        if i==0:\n",
    "            Qy=np.zeros((ny,len(cuy)))  \n",
    "        Qy[i]=cuy\n",
    "\n",
    "\n",
    "    nx=u_v_dataset.u.shape[-1]\n",
    "    nb=sigma*4\n",
    "    for i  in range(nx):\n",
    "        ux=np.zeros(nx)\n",
    "        ux[i]=1\n",
    "        ux=np.concatenate([ux[-nb:],ux,ux[:nb]],axis=0)\n",
    "        filtered=gaussian_filter(ux, scale_filter[1], mode='constant').reshape([-1])\n",
    "        temp=xr.Dataset(data_vars=dict(u=([\"x\"],filtered)),\\\n",
    "                            coords=dict(x=np.arange(filtered.shape[0]))).coarsen({'x': sigma},\n",
    "             boundary='trim').mean()\n",
    "        cux=temp.u.values\n",
    "        if i==0:\n",
    "            Qx=np.zeros((nx,len(cux)))  \n",
    "        Qx[i]=cux\n",
    "\n",
    "    [QQx,_]=np.linalg.qr(Qx,mode='reduced')\n",
    "    [QQy,_]=np.linalg.qr(Qy,mode='reduced')\n",
    "    return QQy,QQx,Qx,Qy\n",
    "def compute_quadratic_form(yc,dy,dx,sigma):\n",
    "    sigma2=sigma//2\n",
    "    s=sigma*4+1\n",
    "    m=sigma*5+1\n",
    "    n=sigma*6+1\n",
    "    yh=yc*sigma-4*sigma2\n",
    "\n",
    "    u=np.zeros(s)\n",
    "    u[sigma*2]=1\n",
    "    g=gaussian_filter(u,sigma2,mode='constant')\n",
    "\n",
    "    gy=np.zeros(m)\n",
    "    gx=np.zeros(m)\n",
    "    \n",
    "    gy_1=np.zeros(m)\n",
    "    gx_1=np.zeros(m)\n",
    "    \n",
    "    dgy=np.zeros(n)\n",
    "    dgx=np.zeros(n)\n",
    "\n",
    "    yh_1=yh-sigma\n",
    "    for i in range(sigma):\n",
    "        gx[i:i+s]+=g/np.sum(g)/sigma\n",
    "        gy[i:i+s]+=g*dy[yh+i:yh+i+s]/np.sum(g*dy[yh+i:yh+i+s])/sigma\n",
    "        gx_1[i:i+s]+=g/np.sum(g)/sigma\n",
    "        gy_1[i:i+s]+=g*dy[yh_1+i:yh_1+i+s]/np.sum(g*dy[yh_1+i:yh_1+i+s])/sigma\n",
    "    \n",
    "    dgy[:m]=-gy_1\n",
    "    dgy[-m:]+=gy\n",
    "    dgy=dgy/np.sum(dy[yh_1:yh])\n",
    "    \n",
    "    dgx[:m]=-gx_1\n",
    "    dgx[-m:]+=gx\n",
    "    dgx=dgx/dx\n",
    "    \n",
    "    n1=n+1\n",
    "    Kx=np.zeros((m**2,n1**2))\n",
    "    Ky=np.zeros((m**2,n1**2))\n",
    "    for i in range(m**2):\n",
    "        iy=i//m\n",
    "        ix=i%m\n",
    "        gi=gy[iy]*gx[ix]\n",
    "        for j in range(n1**2):\n",
    "            jy=j//n1\n",
    "            jx=j%n1\n",
    "            jx_1=jx-sigma\n",
    "            jy_1=jy-sigma\n",
    "            if jx_1>=0 and jx_1<m and jy<m :\n",
    "                gjx_1=gy[jy]*gx[jx_1]/dx\n",
    "            else:\n",
    "                gjx_1=0\n",
    "            if jy<m and jx<m:\n",
    "                gj=gy[jy]*gx[jx]/dx\n",
    "            else:\n",
    "                gj=0\n",
    "            K1=gi*(gjx_1-gj)\n",
    "\n",
    "            if jy_1>=0 and jy_1<m and jx<m:\n",
    "                gjy_1=gy[jy_1]*gx[jx]/dy[yh+jy_1]\n",
    "            else:\n",
    "                gjy_1=0\n",
    "            if jy<m and jx<m:\n",
    "                gj=gy[jy]*gx[jx]/dy[yh+jy]\n",
    "            else:\n",
    "                gj=0\n",
    "            K2=gi*(gjy_1-gj)\n",
    "\n",
    "\n",
    "            if iy==jy and ix==jx-1:\n",
    "                K3=gi/dx\n",
    "            elif iy==jy and ix==jx:\n",
    "                K3=-gi/dx\n",
    "            else:\n",
    "                K3=0\n",
    "\n",
    "            if ix==jx and iy==jy-1:\n",
    "                K4=gi/dy[iy+yh]\n",
    "            elif ix==jx and iy==jy:\n",
    "                K4=-gi/dy[iy+yh]\n",
    "            else:\n",
    "                K4=0\n",
    "\n",
    "            Kx[i,j]=K1-K3\n",
    "            Ky[i,j]=K2-K4\n",
    "    return Kx,Ky\n",
    "def download_raw(typenum):\n",
    "    if typenum==0:\n",
    "        cat = open_catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/ocean/GFDL_CM2.6.yaml\")\n",
    "        ds=cat[\"GFDL_CM2_6_control_ocean_surface\"].to_dask()\n",
    "        ds=ds.drop(\\\n",
    "                    'biomass_p chl dic htotal irr_mix kw o2 po4 sea_level sea_level_sq surface_salt nv st_ocean_sub01 xt_ocean yt_ocean'.split()\\\n",
    "                       )\n",
    "        filename='/scratch/zanna/data/cm2.6/surf-data.zarr'\n",
    "        print('saving 3d data',flush=True)\n",
    "    else:\n",
    "        cat = open_catalog(\"https://raw.githubusercontent.com/pangeo-data/pangeo-datastore/master/intake-catalogs/ocean/GFDL_CM2.6.yaml\")\n",
    "        ds  = cat[\"GFDL_CM2_6_control_ocean_3D\"].to_dask()\n",
    "        filename='/scratch/zanna/data/cm2.6/3D-data.zarr'\n",
    "    save_fun(ds,filename)\n",
    "    \n",
    "    if typenum==0:\n",
    "        print('\\t saved 3d data successfully',flush=True)\n",
    "    else:\n",
    "        print('\\t saved surf data successfully',flush=True)\n",
    "def options(string_input=[]):\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument(\"-s\",\"--sigma\",type=int,default=0)\n",
    "    parser.add_argument(\"-t\",\"--type\",type=int,default=0)\n",
    "    parser.add_argument(\"--test\",type=int,default=0)\n",
    "    parser.add_argument(\"-p\",\"--projection\",type=int,default=0)\n",
    "    parser.add_argument(\"-b\",\"--batch\",type=int,default=4)\n",
    "    parser.add_argument(\"--clean3d\",type=int,default=0)\n",
    "    parser.add_argument(\"--rewrite\",type=int,default=0)\n",
    "    if len(string_input)==0:\n",
    "        return parser.parse_args()\n",
    "    else:\n",
    "        return parser.parse_args(string_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4800a878",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'args=options(\"-s 4 -t 1 --test 1 -p 1\".split())\\ncoarsen_save(args.sigma,             args.type,             testflag=bool(args.test),             projection=bool(args.projection))'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "sigma=args.sigma\n",
    "typenum=args.type\n",
    "testflag=bool(args.test)\n",
    "projection=bool(args.projection)'''\n",
    "\n",
    "\n",
    "'''args=options(\"-s 4 -t 1 --test 1 -p 1\".split())\n",
    "coarsen_save(args.sigma,\\\n",
    "             args.type,\\\n",
    "             testflag=bool(args.test),\\\n",
    "             projection=bool(args.projection))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a164f3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_residues(dimens=[30,40,-50,-35],lognorm=False,d1=10,d2=20):\n",
    "    Z0=xr.open_zarr('/scratch/zanna/data/cm2.6/coarse-surf-data-sigma-4.zarr').isel(time=0)\n",
    "    nrows=3\n",
    "    ncols=3\n",
    "    if len(dimens)==0:\n",
    "        ZZ=Z0#.sel(xu_ocean=slice(30,40),yu_ocean=slice(-45,-30))\n",
    "    else:\n",
    "        ZZ=Z0.sel(xu_ocean=slice(dimens[0],dimens[1]),yu_ocean=slice(dimens[2],dimens[3]))\n",
    "    xx=ZZ.xu_ocean.values\n",
    "    yy=ZZ.yu_ocean.values[::-1]\n",
    "    fig,axs=plt.subplots(nrows,ncols,figsize=(d2,d1))\n",
    "    vrnames=['Su','Sv','ST']\n",
    "    for ii in range(nrows):\n",
    "        vrname=vrnames[ii]\n",
    "        forcing=['','_r']\n",
    "        titles=['','_0','_r']\n",
    "        titles=[vrname+tt for tt in titles]\n",
    "        forcing=[vrname+ff for ff in forcing]\n",
    "        Sr=ZZ[forcing[1]].values\n",
    "        S=ZZ[forcing[0]].values\n",
    "        S=[S,S-Sr,Sr]\n",
    "        for j in range(len(S)):\n",
    "            jj=j\n",
    "            ax=axs[ii,jj]\n",
    "            SIJ=S[j][::-1]\n",
    "            smax=np.amax(np.abs(SIJ[SIJ==SIJ]))\n",
    "            if lognorm:\n",
    "                SIJ=np.log10(np.abs(SIJ))\n",
    "                smax=np.log10(smax)\n",
    "                neg=ax.imshow(SIJ,vmin=-4,vmax=smax,cmap='PuOr',extent=[xx[0],xx[-1],yy[-1],yy[0]])\n",
    "            else:\n",
    "                neg=ax.imshow(SIJ,vmin=-smax,vmax=smax,cmap='PuOr',extent=[xx[0],xx[-1],yy[-1],yy[0]])\n",
    "            divider = make_axes_locatable(ax)\n",
    "            cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "            fig.colorbar(neg,cax=cax)\n",
    "            if lognorm:\n",
    "                ax.set_title('log10 |'+titles[j]+'|')\n",
    "            else:\n",
    "                ax.set_title(titles[j]+' (1e-14 m2s-4)')\n",
    "def adjust_reflections(Qx,sigma):\n",
    "    nb=4*sigma\n",
    "    Qx_=Qx[nb:-nb,:]*1\n",
    "    Qx1=Qx[:nb,:]\n",
    "    Qx1=Qx1[::-1,:]\n",
    "    Qx2=Qx[-nb:,:]\n",
    "    Qx2=Qx2[::-1,:]\n",
    "    Qx_[:nb,:]+=Qx1\n",
    "    Qx_[-nb:,:]+=Qx2\n",
    "    return Qx_            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7685948e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'visualize_residues(lognorm=True,dimens=[],d1=10,d2=20)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''visualize_residues(lognorm=True,dimens=[],d1=10,d2=20)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "577b57c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"sigmas=[4,8,12,16]\\nQXS=[]\\nQYS=[]\\nfor i in range(len(sigmas)):\\n    sigma=sigmas[i]\\n    QQx,QQy,Qx,Qy=compute_projections(sigma,stratind=0)\\n    QXS.append(Qx)\\n    QYS.append(Qy)\\nfig,axs=plt.subplots(1,4,figsize=(20,5))\\nfor i in range(len(sigmas)):\\n    sigma=sigmas[i]\\n    ax=axs[i]\\n    Qx,Qy=QXS[i],QYS[i]\\n    _,sx,_=np.linalg.svd(Qx)\\n    ax.semilogy(sx[:-8*sigma]/sx[0],label='across longitude')\\n    _,sy,_=np.linalg.svd(Qy)\\n    ax.semilogy(sy/sy[0],label='across latitude')\\n    ax.set_title('Singular Values of Coarse-graining sigma='+str(sigma))\\n    ax.legend()\\n    ax.grid()\\n    ax.set_ylabel('singular values')\\n    ax.set_xlabel('index')\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''sigmas=[4,8,12,16]\n",
    "QXS=[]\n",
    "QYS=[]\n",
    "for i in range(len(sigmas)):\n",
    "    sigma=sigmas[i]\n",
    "    QQx,QQy,Qx,Qy=compute_projections(sigma,stratind=0)\n",
    "    QXS.append(Qx)\n",
    "    QYS.append(Qy)\n",
    "fig,axs=plt.subplots(1,4,figsize=(20,5))\n",
    "for i in range(len(sigmas)):\n",
    "    sigma=sigmas[i]\n",
    "    ax=axs[i]\n",
    "    Qx,Qy=QXS[i],QYS[i]\n",
    "    _,sx,_=np.linalg.svd(Qx)\n",
    "    ax.semilogy(sx[:-8*sigma]/sx[0],label='across longitude')\n",
    "    _,sy,_=np.linalg.svd(Qy)\n",
    "    ax.semilogy(sy/sy[0],label='across latitude')\n",
    "    ax.set_title('Singular Values of Coarse-graining sigma='+str(sigma))\n",
    "    ax.legend()\n",
    "    ax.grid()\n",
    "    ax.set_ylabel('singular values')\n",
    "    ax.set_xlabel('index')'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c524c751",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_inverse_span(sigma):\n",
    "    QQx,QQy,Qx,Qy=compute_projections(sigma,stratind=0)\n",
    "    Qx=adjust_reflections(Qx,sigma)\n",
    "    u,s,v=np.linalg.svd(Qx)\n",
    "    iQx=u[:,:len(s)-4*sigma]@np.diag(1/s[:-4*sigma])@v[:-4*sigma,:]\n",
    "\n",
    "    u,s,v=np.linalg.svd(Qy)\n",
    "    iQy=u[:,:len(s)]@np.diag(1/s)@v\n",
    "    SQx=iQx*1\n",
    "    for i in range(iQx.shape[1]):\n",
    "        qx=iQx[:,i]\n",
    "        ii=np.argmax(np.abs(qx))\n",
    "        qx=np.concatenate([qx[ii:],qx[:ii]],axis=0)\n",
    "        SQx[:,i]=qx\n",
    "    mx=iQx.shape[0]//2\n",
    "    SQx=np.abs(np.concatenate([SQx[mx:],SQx[:mx]],axis=0))\n",
    "\n",
    "\n",
    "    SQy=iQy*1\n",
    "    for i in range(iQy.shape[1]):\n",
    "        qx=iQy[:,i]\n",
    "        ii=np.argmax(qx)\n",
    "        SQy[:,i]=np.concatenate([qx[ii:],qx[:ii]],axis=0)\n",
    "    my=iQy.shape[0]//2\n",
    "    SQy=np.abs(np.concatenate([SQy[my:],SQy[:my]],axis=0))\n",
    "    MX=iQx.shape[1]\n",
    "    MX4=MX//4\n",
    "    mx2=mx//2\n",
    "    S=12*sigma\n",
    "    span=np.arange(-S,S)\n",
    "    nspan=span/sigma\n",
    "    fig,axs=plt.subplots(1,2,figsize=(15,5))\n",
    "    mSQx=np.mean(SQx,axis=1)\n",
    "    sSQx=np.std(SQx,axis=1)\n",
    "    axs[0].semilogy(nspan,mSQx[mx+span],label='average')\n",
    "    axs[0].fill_between(nspan,mSQx[mx+span]-sSQx[mx+span],mSQx[mx+span]+sSQx[mx+span],alpha=0.2,color='blue',label='+-1 std')\n",
    "    axs[0].set_title('Inverse Coarse-Graining('+str(sigma)+') Span in Longitude')\n",
    "    axs[0].set_ylim([5e-4,np.amax(SQx)*1.2])\n",
    "    axs[0].set_xlabel('longitude grid points from center ('+str(sigma*7.5)+'km each)')\n",
    "    axs[0].axvline(x=-3,linestyle='--',color='r')\n",
    "    axs[0].axvline(x=3,linestyle='--',color='r')\n",
    "    axs[0].legend()\n",
    "\n",
    "    mSQy=np.mean(SQy,axis=1)\n",
    "    sSQy=np.std(SQy,axis=1)\n",
    "    axs[1].semilogy(nspan,mSQy[my+span],label='average')\n",
    "    axs[1].fill_between(nspan,mSQy[my+span]-sSQy[my+span],mSQy[my+span]+sSQy[my+span],alpha=0.2,color='blue',label='+-1 std')\n",
    "    axs[1].set_ylim([1e-4,np.amax(SQy)*1.1])\n",
    "    axs[1].set_title('Inverse Coarse-Graining('+str(sigma)+') Span in Latitude')\n",
    "    axs[1].set_xlabel('latitude grid points from center ('+str(sigma*7.5)+'km each at equator)')\n",
    "    axs[1].axvline(x=-3,linestyle='--',color='r')\n",
    "    axs[1].axvline(x=3,linestyle='--',color='r')\n",
    "    axs[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88634fa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotting_projections():\n",
    "    sigmas=[4,8,12,16]\n",
    "    QXS=[]\n",
    "    QYS=[]\n",
    "    for i in range(len(sigmas)):\n",
    "        sigma=sigmas[i]\n",
    "        QQx,QQy,Qx,Qy=compute_projections(sigma,stratind=0)\n",
    "        QXS.append(Qx)\n",
    "        QYS.append(Qy)\n",
    "    fig,axs=plt.subplots(1,4,figsize=(20,5))\n",
    "    for i in range(len(sigmas)):\n",
    "        sigma=sigmas[i]\n",
    "        ax=axs[i]\n",
    "        Qx,Qy=QXS[i],QYS[i]\n",
    "        _,sx,_=np.linalg.svd(Qx)\n",
    "        ax.semilogy(sx[:-8*sigma]/sx[0],label='across longitude')\n",
    "        _,sy,_=np.linalg.svd(Qy)\n",
    "        ax.semilogy(sy/sy[0],label='across latitude')\n",
    "        ax.set_title('Singular Values of Coarse-graining sigma='+str(sigma))\n",
    "        ax.legend()\n",
    "        ax.grid()\n",
    "        ax.set_ylabel('singular values')\n",
    "        ax.set_xlabel('index')\n",
    "\n",
    "    SQQx=QQx*1\n",
    "    for i in range(QQx.shape[1]):\n",
    "        qx=QQx[:,i]\n",
    "        ii=np.argmax(qx)\n",
    "        qx=np.concatenate([qx[ii:],qx[:ii]],axis=0)\n",
    "        SQQx[:,i]=qx\n",
    "    mx=QQx.shape[0]//2\n",
    "    SQQx=np.concatenate([SQQx[mx:],SQQx[:mx]],axis=0)\n",
    "\n",
    "\n",
    "    SQQy=QQy*1\n",
    "    for i in range(QQy.shape[1]):\n",
    "        qx=QQy[:,i]\n",
    "        ii=np.argmax(qx)\n",
    "        SQQy[:,i]=np.concatenate([qx[ii:],qx[:ii]],axis=0)\n",
    "    my=QQy.shape[0]//2\n",
    "    SQQy=np.concatenate([SQQy[my:],SQQy[:my]],axis=0)\n",
    "\n",
    "\n",
    "    SSQQx=np.sort(SQQx**2,axis=1)\n",
    "    SSQQx=SSQQx[:,::-1]\n",
    "    MX=QQx.shape[1]\n",
    "    MX4=MX//4\n",
    "    mx2=mx//2\n",
    "    S=40\n",
    "    span=np.arange(-S,S)\n",
    "\n",
    "    plt.semilogy(np.abs(SSQQx[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "05bb937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_3d_data():\n",
    "    root='/scratch/zanna/data/cm2.6/'\n",
    "    filename=root+'3D-data.zarr'\n",
    "    filename1=root+'3D-data-1.zarr'\n",
    "    ds_data=xr.open_zarr(filename)\\\n",
    "            .isel(st_ocean=np.array([0,10,15,20])).drop('salt')\n",
    "    save_fun(ds_data,filename1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3a25ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fun(uv_data,filename):\n",
    "    dd=4\n",
    "    for j in range(len(uv_data.time.values)//dd):\n",
    "        if j==0:\n",
    "            uv_data.isel(time=range(j*dd,(j+1)*dd)).to_zarr(filename,mode='w')\n",
    "        else:\n",
    "            uv_data.isel(time=range(j*dd,(j+1)*dd)).to_zarr(filename,append_dim=\"time\",mode='a')\n",
    "        print('\\t\\t'+str(j*dd),flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "857d7506",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yc=200\\nKx,Ky=compute_quadratic_form(yc,dy,dx,sigma)\\n\\nraw_data_address=\\'/scratch/zanna/data/cm2.6/3D-data.zarr\\'\\nstratinds=np.array([0])\\nu_v_dataset=xr.open_zarr(raw_data_address)                .chunk(chunks={\"time\":1})                .isel(st_ocean=stratinds)                .drop(\"salt nv st_edges_ocean xt_ocean yt_ocean\".split())\\nu_v_dataset=u_v_dataset.isel(time=np.arange(1),st_ocean=np.arange(1))\\nu_v_dataset=u_v_dataset.drop(\"time st_ocean\".split())\\n\\nyi=yc*sigma\\nu_v_datasetj=u_v_dataset\\nSu=np.zeros(u_v_datasetj.u.shape[2]-n1)\\nuu=np.stack([u_v_datasetj.u.values[0,0],                u_v_datasetj.v.values[0,0],                  u_v_datasetj.temp.values[0,0] ],axis=0)\\nfor xi in range(u_v_datasetj.u.shape[2]-n1):\\n    t=uu[2,yi:yi+n1,xi:xi+n1].reshape([-1,1])\\n    v=uu[1,yi:yi+m,xi:xi+m].reshape([1,-1])\\n    u=uu[0,yi:yi+m,xi:xi+m].reshape([1,-1])\\n    Su[xi]=u@Kx@t+v@Ky@t\\n\\nx=u_v_dataset.xu_ocean.values\\ny=u_v_dataset.yu_ocean.values\\ndx=x[1:]-x[:-1]\\ndy=y[1:]-y[:-1]\\n\\ndx=np.reshape(dx,(1,-1))\\ndx=[dx for i in range(len(y)-1)]\\ndx=np.concatenate(dx,axis=0)\\n#dx=np.stack([dx],axis=0)\\n\\ndy=np.reshape(dy,(-1,1))\\ndy=[dy for i in range(len(x)-1)]\\ndy=np.concatenate(dy,axis=1)\\n#dy=np.stack([dy],axis=0)\\ngrid_data=xr.Dataset(data_vars=dict(dxu=([\"yu_ocean\",\"xu_ocean\"],dx),                                    dyu=([\"yu_ocean\",\"xu_ocean\"],dy)),                        coords=dict(xu_ocean=x[:-1],yu_ocean=y[:-1]))\\n\\n\\n\\nu_v_datasetj=u_v_dataset\\n\\nu=np.stack([u_v_datasetj.u.values,            u_v_datasetj.v.values,              u_v_datasetj.temp.values ],axis=0)\\n\\nuv=xr.Dataset(data_vars=dict(usurf=([\"time\",\"yu_ocean\",\"xu_ocean\"],u[0,0]),                                vsurf=([\"time\",\"yu_ocean\",\"xu_ocean\"],u[1,0]),                                 surface_temp=([\"time\",\"yu_ocean\",\"xu_ocean\"],u[2,0])),                    coords=dict(xu_ocean=x,yu_ocean=y,time=np.arange(1)))\\nforcing=eddy_forcing(uv, grid_data,sigma,nan_or_zero=\\'nan\\',typenum=0)'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''yc=200\n",
    "Kx,Ky=compute_quadratic_form(yc,dy,dx,sigma)\n",
    "\n",
    "raw_data_address='/scratch/zanna/data/cm2.6/3D-data.zarr'\n",
    "stratinds=np.array([0])\n",
    "u_v_dataset=xr.open_zarr(raw_data_address)\\\n",
    "                .chunk(chunks={\"time\":1})\\\n",
    "                .isel(st_ocean=stratinds)\\\n",
    "                .drop(\"salt nv st_edges_ocean xt_ocean yt_ocean\".split())\n",
    "u_v_dataset=u_v_dataset.isel(time=np.arange(1),st_ocean=np.arange(1))\n",
    "u_v_dataset=u_v_dataset.drop(\"time st_ocean\".split())\n",
    "\n",
    "yi=yc*sigma\n",
    "u_v_datasetj=u_v_dataset\n",
    "Su=np.zeros(u_v_datasetj.u.shape[2]-n1)\n",
    "uu=np.stack([u_v_datasetj.u.values[0,0],\\\n",
    "                u_v_datasetj.v.values[0,0],\\\n",
    "                  u_v_datasetj.temp.values[0,0] ],axis=0)\n",
    "for xi in range(u_v_datasetj.u.shape[2]-n1):\n",
    "    t=uu[2,yi:yi+n1,xi:xi+n1].reshape([-1,1])\n",
    "    v=uu[1,yi:yi+m,xi:xi+m].reshape([1,-1])\n",
    "    u=uu[0,yi:yi+m,xi:xi+m].reshape([1,-1])\n",
    "    Su[xi]=u@Kx@t+v@Ky@t\n",
    "\n",
    "x=u_v_dataset.xu_ocean.values\n",
    "y=u_v_dataset.yu_ocean.values\n",
    "dx=x[1:]-x[:-1]\n",
    "dy=y[1:]-y[:-1]\n",
    "\n",
    "dx=np.reshape(dx,(1,-1))\n",
    "dx=[dx for i in range(len(y)-1)]\n",
    "dx=np.concatenate(dx,axis=0)\n",
    "#dx=np.stack([dx],axis=0)\n",
    "\n",
    "dy=np.reshape(dy,(-1,1))\n",
    "dy=[dy for i in range(len(x)-1)]\n",
    "dy=np.concatenate(dy,axis=1)\n",
    "#dy=np.stack([dy],axis=0)\n",
    "grid_data=xr.Dataset(data_vars=dict(dxu=([\"yu_ocean\",\"xu_ocean\"],dx),\\\n",
    "                                    dyu=([\"yu_ocean\",\"xu_ocean\"],dy)),\\\n",
    "                        coords=dict(xu_ocean=x[:-1],yu_ocean=y[:-1]))\n",
    "\n",
    "\n",
    "\n",
    "u_v_datasetj=u_v_dataset\n",
    "\n",
    "u=np.stack([u_v_datasetj.u.values,\\\n",
    "            u_v_datasetj.v.values,\\\n",
    "              u_v_datasetj.temp.values ],axis=0)\n",
    "\n",
    "uv=xr.Dataset(data_vars=dict(usurf=([\"time\",\"yu_ocean\",\"xu_ocean\"],u[0,0]),\\\n",
    "                                vsurf=([\"time\",\"yu_ocean\",\"xu_ocean\"],u[1,0]),\\\n",
    "                                 surface_temp=([\"time\",\"yu_ocean\",\"xu_ocean\"],u[2,0])),\\\n",
    "                    coords=dict(xu_ocean=x,yu_ocean=y,time=np.arange(1)))\n",
    "forcing=eddy_forcing(uv, grid_data,sigma,nan_or_zero='nan',typenum=0)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4177ddfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-s SIGMA] [-t TYPE] [--test TEST]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: -f /home/cg3306/.local/share/jupyter/runtime/kernel-49934edc-d46c-444b-8c17-8e4dc4b481a2.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    args=options()\n",
    "    print(args)\n",
    "    if args.clean3d==1:\n",
    "        clean_3d_data()\n",
    "    if args.sigma==0:\n",
    "        #download_raw(args.type)\n",
    "        print(' uncomment the part and resubmit the job, this action requires download')\n",
    "    elif args.sigma>0:\n",
    "        coarsen_save(args.sigma,\\\n",
    "                     args.type,\\\n",
    "                     testflag=bool(args.test),\\\n",
    "                     projection=bool(args.projection),rewrite=bool(args.rewrite))\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
