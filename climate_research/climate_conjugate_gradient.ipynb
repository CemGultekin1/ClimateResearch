{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0911c881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.nn import functional as F\n",
    "import os\n",
    "import json\n",
    "import copy\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import numpy as np\n",
    "import climate_train as ct\n",
    "import sys\n",
    "import scipy\n",
    "import time\n",
    "import argparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57445310",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cg_options(string_input=[]):\n",
    "    parser=argparse.ArgumentParser()\n",
    "    parser.add_argument(\"--iter\",type=int,default=1000)\n",
    "    parser.add_argument(\"--tol\",type=float,default=1e-3)\n",
    "    parser.add_argument(\"-r\",\"--rootdir\",type=str,default='/scratch/cg3306/climate/runs/')\n",
    "    parser.add_argument(\"-o\",\"--outdir\",type=str,default=\"default\")\n",
    "    parser.add_argument(\"--testrun\",type=int,default=0)\n",
    "    parser.add_argument(\"--action\",type=str,default=\"optimize\")\n",
    "    parser.add_argument(\"--model_id\",type=int,default=0)\n",
    "    parser.add_argument(\"--data_address\",type=str,default=\\\n",
    "                        '/scratch/ag7531/mlruns/19/bae994ef5b694fc49981a0ade317bf07/artifacts/forcing/')\n",
    "    parser.add_argument(\"--relog\",type=int,default=0)\n",
    "    parser.add_argument(\"--nworkers\",type=int,default=3)\n",
    "    parser.add_argument(\"--rerun\",type=int,default=0)\n",
    "    parser.add_argument(\"--timing\",type=int,default=0)\n",
    "    parser.add_argument(\"-b\",\"--batch\",type=int,default=1)\n",
    "    #args = parser.parse_args()\n",
    "    if len(string_input)==0:\n",
    "        return parser.parse_args()\n",
    "    return parser.parse_args(string_input)\n",
    "\n",
    "\n",
    "def model_bank(mid):\n",
    "    reg=0\n",
    "    if mid==0:\n",
    "        return {'m':3,'reg':reg}\n",
    "    if mid==1:\n",
    "        return {'m':9,'reg':reg}\n",
    "    if mid==2:\n",
    "        return {'m':21,'reg':reg}\n",
    "\n",
    "def load_from_save(args):\n",
    "    root = args.rootdir +args.outdir\n",
    "    PATH0 = root + \"/last-model-ID\"+str(args.model_id)+\".npy\"\n",
    "    PATH1 = root + \"/best-model-ID\"+str(args.model_id)+\".npy\"\n",
    "    LOG = root + \"/log-ID\"+str(args.model_id)+\".json\"\n",
    "    model=model_bank(args.model_id)\n",
    "    \n",
    "    isdir = os.path.isdir(args.rootdir) \n",
    "    if not isdir:\n",
    "        os.mkdir(args.rootdir)\n",
    "    isdir = os.path.isdir(root) \n",
    "    if not isdir:\n",
    "        os.mkdir(root)\n",
    "    if not args.rerun and os.path.isfile(PATH0):\n",
    "        try:\n",
    "            M=torch.tensor(np.load(PATH0),dtype=torch.float32)\n",
    "            print(\"Loaded the existing model\",flush=True)\n",
    "        except IOError:\n",
    "            M=initialize_model(model['m'])\n",
    "            print(\"No existing model found - new beginnings\",flush=True)\n",
    "    else:\n",
    "        M=initialize_model(model['m'])\n",
    "        print(\"- new beginnings\",flush=True)\n",
    "    if not args.relog:\n",
    "        try: \n",
    "            with open(LOG) as f:\n",
    "                logs = json.load(f)\n",
    "        except IOError:\n",
    "            logs = {\"epoch\":[],\"train-loss\":[],\"test-loss\":[]}\n",
    "    if args.relog:\n",
    "        logs = {\"epoch\":[],\"train-loss\":[],\"test-loss\":[]}\n",
    "    return model,M, logs,PATH0,PATH1,LOG,root\n",
    "\n",
    "def idct22(S4M_,IDCTB):\n",
    "    S4M=torch.zeros(2,IDCTB.shape[0],IDCTB.shape[0])\n",
    "    for j in range(2):\n",
    "        S4M[j]=torch.matmul(IDCTB,torch.matmul(S4M_[j],np.transpose(IDCTB)))\n",
    "    return S4M\n",
    "\n",
    "def compute_moments(M,datagen,m,DCT,S22flag=False,reg=1e-3,scale=1,time_stats=[],time_rec=False):\n",
    "    m2=m**2\n",
    "    tot=0\n",
    "    S4M=torch.zeros(2,m2*2,m2*2,dtype=torch.float32)\n",
    "    if S22flag:\n",
    "        S22=torch.zeros(2,m2*2,m2*2,dtype=torch.float32)\n",
    "    device=ct.get_device()\n",
    "    spread=np.int64( (m-1)/2)\n",
    "    Mu=S4M*2\n",
    "    for uv,mask,Sxy in datagen:\n",
    "        if time_rec:\n",
    "            time_stats.append([])\n",
    "        uv=uv/scale\n",
    "        Sxy=Sxy/scale\n",
    "        \n",
    "        spatxdim=mask.shape[3]\n",
    "        spatydim=mask.shape[2]\n",
    "        spatdim=mask.shape[3]*mask.shape[2]\n",
    "        if time_rec:\n",
    "            tic = time.perf_counter()\n",
    "        uv,mask=uv.to(device),mask.to(device)\n",
    "        outputL=[[] for i in range(2)]\n",
    "        with torch.set_grad_enabled(False):\n",
    "            output=mask*DCT(uv)\n",
    "        output=output[0]\n",
    "        if time_rec:\n",
    "            toc = time.perf_counter()\n",
    "            time_stats[-1].append(toc-tic)\n",
    "        if time_rec:\n",
    "            tic = time.perf_counter()\n",
    "        tot+=mask.sum()\n",
    "        output=output.view([m2*2,-1]) \n",
    "        if S22flag:\n",
    "            Sxy=Sxy.view(2,1,-1)\n",
    "            \n",
    "        #  (C,C) * (C,n) -> (C,n)\n",
    "        uMu=[torch.matmul(M[j],output) for j in range(2)] \n",
    "        #  (C,n) o (C,n) -> (1,n)\n",
    "        uMu=[torch.mul(uMu[j],output).sum(0).view(1,-1) for j in range(2)]\n",
    "        #  (C,n) * (1,n) -> (C,n)\n",
    "        uMu=[torch.mul(output,uMu[j]) for j in range(2)]\n",
    "        #  (C,n) * (n,C)\n",
    "        uMu=[torch.matmul(uMu[j],output.T) for j in range(2)]\n",
    "        if S22flag:\n",
    "            uuS=[output*Sxy[j] for j in range(2)]\n",
    "            uuS=[torch.matmul(uuS[j],output.T) for j in range(2)]\n",
    "        for j in range(2):\n",
    "            S4M[j]=S4M[j]+uMu[j]\n",
    "            if S22flag:\n",
    "                S22[j]=S22[j]+uuS[j]\n",
    "        if time_rec:\n",
    "            toc = time.perf_counter()\n",
    "            time_stats[-1].append(toc-tic)\n",
    "    \n",
    "    S4M=S4M/tot\n",
    "    #print(torch.abs(S4M).mean().item(),torch.abs(M).mean().item())\n",
    "    if S22flag:\n",
    "        S22=S22/tot\n",
    "    else:\n",
    "        return S4M+reg*M,time_stats\n",
    "    return S4M+reg*M,S22,time_stats\n",
    "\n",
    "\n",
    "def cosine_transform(m,nfreq=-1):\n",
    "    device=ct.get_device()\n",
    "    freq=np.array(np.unravel_index(np.arange(m**2),[m,m]))\n",
    "    freqm=np.argsort(freq[0]+freq[1]*(1+1e-3))\n",
    "    freq=freq[:,freqm]\n",
    "    if nfreq>0:\n",
    "        freq=freq[:,:nfreq]\n",
    "    else:\n",
    "        nfreq=m**2\n",
    "    DCT=nn.Conv2d(2, 2*nfreq, m,bias=False).to(device)\n",
    "    DCT.weight.data=DCT.weight.data*0\n",
    "    \n",
    "    \n",
    "    \n",
    "    IDCT=torch.zeros(m**2,nfreq)\n",
    "    for i in range(nfreq):\n",
    "        i0,i1=freq[:,i]\n",
    "        W0=np.cos(np.pi/m * (np.arange(0,m)+1/2) * i0)\n",
    "        W1=np.cos(np.pi/m * (np.arange(0,m)+1/2) * i1)\n",
    "        W=np.matmul(np.reshape(W0,[-1,1]),np.reshape(W1,[1,-1]))\n",
    "        W=W/np.sqrt(np.sum(W**2))\n",
    "        W=torch.tensor(W,dtype=torch.float32)\n",
    "        DCT.weight.data[i,0,:,:]=W\n",
    "        DCT.weight.data[nfreq+i,1,:,:]=W\n",
    "        IDCT[:,i]=W.view(-1)\n",
    "    IDCTB=torch.tensor(scipy.linalg.block_diag(IDCT,IDCT))\n",
    "    return DCT,IDCTB\n",
    "\n",
    "def shift_transform(m):\n",
    "    device=ct.get_device()\n",
    "    m2=m**2\n",
    "    SHT=nn.Conv2d(2, 2*(m2), m,bias=False).to(device)\n",
    "    SHT.weight.data=SHT.weight.data*0\n",
    "    for i in range(m2):\n",
    "        i0,i1=np.unravel_index(i,[m,m])\n",
    "        SHT.weight.data[i,0,i0,i1]=1\n",
    "        SHT.weight.data[m2+i,1,i0,i1]=1\n",
    "    return SHT\n",
    "\n",
    "def initialize_model(m):\n",
    "    return torch.zeros(2,2*m**2,2*m**2,dtype=torch.float32)\n",
    "\n",
    "def conjugate_gradient_algorithm(args):\n",
    "    (_,datagen),_,_,_=load_data(args)\n",
    "    print(\"loaded data\",flush=True)\n",
    "    model,M, logs,PATH0,PATH1,LOG,root=load_from_save(args)\n",
    "    print(\"loaded model\",flush=True)\n",
    "    m=model['m']\n",
    "    reg=model['reg']\n",
    "    DCT=shift_transform(m)\n",
    "    tol=args.tol\n",
    "    max_iter=args.iter\n",
    "    time_stats=[]\n",
    "    if len(M)==0:\n",
    "        M=initialize_model(m)\n",
    "    S4p,S22,time_stats=compute_moments(M,datagen,m,DCT,S22flag=True,time_stats=time_stats,reg=reg,time_rec=args.timing)\n",
    "\n",
    "    r1=-S4p+S22\n",
    "    p1=-S4p+S22\n",
    "    reset=0\n",
    "    alpha=torch.zeros(2,dtype=torch.float32)\n",
    "    beta=torch.zeros(2,dtype=torch.float32)\n",
    "    err=torch.zeros(2,dtype=torch.float32)\n",
    "    for i in range(max_iter):\n",
    "        p0=p1*1\n",
    "        r0=r1*1\n",
    "        \n",
    "        S4p0,time_stats=compute_moments(p0,datagen,m,DCT,S22flag=False,time_stats=time_stats,reg=reg,time_rec=args.timing)\n",
    "        \n",
    "        for j in range(2):\n",
    "            alpha[j]=torch.norm(r0[j].view(-1,1))**2/(torch.matmul(p0[j].view(1,-1),S4p0[j].view(-1,1)))\n",
    "            r1[j]=r0[j]-alpha[j]*S4p0[j]\n",
    "            beta[j]=torch.norm(r1[j].view(-1,1))**2/(torch.norm(r0[j].view(-1,1))**2)\n",
    "            p1[j]=r1[j]+beta[j]*p0[j]\n",
    "            M[j]=M[j]+alpha[j]*p0[j]\n",
    "            err[j]=torch.norm(r1[j].view(-1,1))\n",
    "        serr=torch.norm(err).item()\n",
    "        print('#'+str(i)+' err: '+str(err),flush=True)\n",
    "        logs['train-loss'].append(serr)\n",
    "        logs['test-loss'].append(serr)\n",
    "        \n",
    "        with open(PATH0,'wb') as outfile:\n",
    "            np.save(outfile,M.numpy())\n",
    "        if logs['test-loss'][-1]==np.min(logs['test-loss']):\n",
    "            with open(PATH1,'wb') as outfile:\n",
    "                np.save( outfile,M.numpy())\n",
    "        with open(LOG, 'w') as outfile:\n",
    "            json.dump(logs, outfile)\n",
    "        reset+=1\n",
    "        if err[0].item()<tol:\n",
    "            return M,err,time_stats \n",
    "        else:\n",
    "            if reset>20:\n",
    "                if np.mean(logs['train-loss'][-4:-1])/logs['train-loss'][-1] < 1.01 : \n",
    "                    S4p,time_stats=compute_moments(M,datagen,m,DCT,S22flag=False,time_stats=time_stats,reg=reg,time_rec=args.timing)\n",
    "                    r1=-S4p+S22\n",
    "                    p1=-S4p+S22\n",
    "                    reset=0\n",
    "    return M,err,time_stats #idct22(M,IDCTB)\n",
    "   \n",
    "\n",
    "def load_data(args):\n",
    "    model=model_bank(args.model_id)\n",
    "    m=model['m']\n",
    "    spread= np.int64((m-1)/2)\n",
    "    ds_zarr=xr.open_zarr(args.data_address)\n",
    "    tot_time=ds_zarr.time.shape[0]\n",
    "    params={'batch_size':args.batch,'shuffle':False, 'num_workers':args.nworkers}\n",
    "    partition=ct.physical_domains(1,validation=False)\n",
    "    if args.testrun>0:\n",
    "        sub_tot_time=args.testrun\n",
    "        rng = np.random.default_rng(0)\n",
    "        indices=np.sort(rng.choice(tot_time,size=sub_tot_time,replace=False))\n",
    "        ds_zarr=ds_zarr.sel(time=ds_zarr.time[indices].data)\n",
    "    training_set = ct.Dataset(ds_zarr,partition['train'],spread=spread)\n",
    "    training_generator = torch.utils.data.DataLoader(training_set, **params,collate_fn=ct.default_collate)\n",
    "    \n",
    "    test_set = ct.Dataset(ds_zarr,partition['test'],spread=spread)\n",
    "    test_generator = torch.utils.data.DataLoader(test_set, **params,collate_fn=ct.default_collate)\n",
    "    \n",
    "    earth_set = ct.Dataset(ds_zarr,partition['earth'],spread=spread)\n",
    "    earth_generator = torch.utils.data.DataLoader(earth_set, **params,collate_fn=ct.default_collate)\n",
    "    return (training_set,training_generator),\\\n",
    "                (test_set,test_generator),\\\n",
    "                    (earth_set,earth_generator),\\\n",
    "                        ds_zarr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52294053",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analysis(args):\n",
    "    _,_,(dataset,_),_=load_data(args)\n",
    "    print(\"loaded data\",flush=True)\n",
    "    model,M, logs,PATH0,PATH1,LOG,root=load_from_save(args)\n",
    "    device=ct.get_device()\n",
    "    MSELOC=root+'/MSE-ID'+str(args.model_id)+'.npy'\n",
    "    SC2LOC=root+'/SC2-ID'+str(args.model_id)+'.npy'\n",
    "    MSE=torch.zeros(2,dataset.dimens[0]-dataset.spread*2, dataset.dimens[1]-dataset.spread*2)\n",
    "    SC2=torch.zeros(2,dataset.dimens[0]-dataset.spread*2, dataset.dimens[1]-dataset.spread*2)\n",
    "    print(MSELOC)\n",
    "    m=model['m']\n",
    "    DCT=shift_transform(m)\n",
    "    arr=np.arange(len(dataset))\n",
    "    np.random.shuffle(arr)\n",
    "    for i in range(len(dataset)):\n",
    "        uv,mask,Sxy=dataset[arr[i]]\n",
    "        uv=torch.stack([uv]).to(device)\n",
    "        spatxdim=mask.shape[2]\n",
    "        spatydim=mask.shape[1]\n",
    "        with torch.set_grad_enabled(False):\n",
    "            output=DCT.forward(uv)\n",
    "        output=output[0].view(2*m**2,-1)        \n",
    "        \n",
    "        #  (C,C) * (C,n) -> (C,n)\n",
    "        uMu=[torch.matmul(M[j],output) for j in range(2)] \n",
    "        #  (C,n) o (C,n) -> (1,n)\n",
    "        Sxy_=[torch.mul(uMu[j],output).sum(0).view(spatydim,spatxdim) for j in range(2)]\n",
    "        ERR=Sxy*1\n",
    "        for j in range(2):\n",
    "            ERR[j]-=Sxy_[j]\n",
    "        SC2=SC2 + Sxy**2\n",
    "        MSE=MSE + ERR**2\n",
    "        if i%10==0:\n",
    "            MSE_=MSE.numpy()\n",
    "            SC2_=SC2.numpy()\n",
    "            with open(MSELOC, 'wb') as f:\n",
    "                np.save(f, MSE_/(i+1))\n",
    "            with open(SC2LOC, 'wb') as f:\n",
    "                np.save(f, SC2_/(i+1))\n",
    "            print('\\t #'+str(i),flush=True)\n",
    "    MSE_=MSE.numpy()\n",
    "    SC2_=SC2.numpy()\n",
    "    with open(MSELOC, 'wb') as f:\n",
    "        np.save(f, MSE_/(i+1))\n",
    "    with open(SC2LOC, 'wb') as f:\n",
    "        np.save(f, SC2_/(i+1))\n",
    "    print('analysis is done',flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4c5a085",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"args=cg_options(string_input=['--outdir','2021-06-29-CG','--tol','1e-3',                              '--rerun','0','--relog','0','--testrun','1','--model_id','2','--timing','0'])\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''args=cg_options(string_input=['--outdir','2021-06-29-CG','--tol','1e-3',\\\n",
    "                              '--rerun','0','--relog','0','--testrun','1','--model_id','2','--timing','0'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4172849a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# --outdir 2021-06-28-CG --iter 1000 --testrun 1000 --nworkers 5 --model_id $SLURM_ARRAY_TASK_ID --action analysis\n",
    "args=cg_options(string_input=['--outdir','2021-06-29-CG','--tol','1e-3',\\\n",
    "                              '--rerun','0','--relog','0','--testrun','1','--model_id','2','--timing','0'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5914ca9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data\n",
      "Loaded the existing model\n",
      "/scratch/cg3306/climate/runs/2021-06-29-CG/MSE-ID2.npy\n",
      "\t #0\n",
      "analysis is done\n"
     ]
    }
   ],
   "source": [
    "'''analysis(args)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "397a1640",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'_,_,(dataset,_),_=load_data(args)\\nprint(\"loaded data\",flush=True)\\nmodel,M, logs,PATH0,PATH1,LOG,root=load_from_save(args)\\ndevice=ct.get_device()\\nMSELOC=root+\\'/MSE-ID\\'+str(args.model_id)+\\'.npy\\'\\nSC2LOC=root+\\'/SC2-ID\\'+str(args.model_id)+\\'.npy\\'\\nMSE=torch.zeros(2,dataset.dimens[0]-dataset.spread*2, dataset.dimens[1]-dataset.spread*2)\\nSC2=torch.zeros(2,dataset.dimens[0]-dataset.spread*2, dataset.dimens[1]-dataset.spread*2)\\nprint(MSELOC)\\nm=model[\\'m\\']\\nDCT=shift_transform(m)\\narr=np.arange(len(dataset))\\nnp.random.shuffle(arr)\\nfor i in range(len(dataset)):\\n    uv,mask,Sxy=dataset[arr[i]]\\n    uv=torch.stack([uv]).to(device)\\n    with torch.set_grad_enabled(False):\\n        output=DCT.forward(uv)\\n    output=output[0].to(torch.device(\"cpu\"))\\n    Sxy_=Sxy*1\\n    for k in range(2):\\n        output_=output*1\\n        for j in range(M.shape[1]):\\n            output_[j]=(M[k,j,:].view(-1,1,1)*output).sum(0)\\n        Sxy_[k]=(output_*output).sum(0)\\n    SC2=SC2 + Sxy**2\\n    MSE=MSE + (Sxy-Sxy_)**2\\n    break'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''_,_,(dataset,_),_=load_data(args)\n",
    "print(\"loaded data\",flush=True)\n",
    "model,M, logs,PATH0,PATH1,LOG,root=load_from_save(args)\n",
    "device=ct.get_device()\n",
    "MSELOC=root+'/MSE-ID'+str(args.model_id)+'.npy'\n",
    "SC2LOC=root+'/SC2-ID'+str(args.model_id)+'.npy'\n",
    "MSE=torch.zeros(2,dataset.dimens[0]-dataset.spread*2, dataset.dimens[1]-dataset.spread*2)\n",
    "SC2=torch.zeros(2,dataset.dimens[0]-dataset.spread*2, dataset.dimens[1]-dataset.spread*2)\n",
    "print(MSELOC)\n",
    "m=model['m']\n",
    "DCT=shift_transform(m)\n",
    "arr=np.arange(len(dataset))\n",
    "np.random.shuffle(arr)\n",
    "for i in range(len(dataset)):\n",
    "    uv,mask,Sxy=dataset[arr[i]]\n",
    "    uv=torch.stack([uv]).to(device)\n",
    "    with torch.set_grad_enabled(False):\n",
    "        output=DCT.forward(uv)\n",
    "    output=output[0].to(torch.device(\"cpu\"))\n",
    "    Sxy_=Sxy*1\n",
    "    for k in range(2):\n",
    "        output_=output*1\n",
    "        for j in range(M.shape[1]):\n",
    "            output_[j]=(M[k,j,:].view(-1,1,1)*output).sum(0)\n",
    "        Sxy_[k]=(output_*output).sum(0)\n",
    "    SC2=SC2 + Sxy**2\n",
    "    MSE=MSE + (Sxy-Sxy_)**2\n",
    "    break'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4bc1749",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''args=cg_options(string_input=['--iter','5','--tol','1e-3',\\\n",
    "                              '--rerun','1','--relog','1','--testrun','1','--model_id','3','--timing','1'])'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e8062ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data\n",
      "- new beginnings\n",
      "loaded model\n",
      "#0 err: tensor([373.4859, 321.0286])\n",
      "#1 err: tensor([185.8229, 161.9241])\n",
      "#2 err: tensor([117.6426, 104.7633])\n",
      "#3 err: tensor([81.4258, 70.7428])\n",
      "#4 err: tensor([58.8485, 45.0566])\n"
     ]
    }
   ],
   "source": [
    "'''M,err,time_stats=conjugate_gradient_algorithm(args)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ea50532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M,err,time_stats=conjugate_gradient_algorithm(args)'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''args=cg_options(string_input=['--iter','30','--tol','1e-3',\\\n",
    "                              '--rerun','1','--relog','1','--testrun','1','--model_id','2','--timing','1'])'''\n",
    "\n",
    "\n",
    "'''M,err,time_stats=conjugate_gradient_algorithm(args)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b2efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''carpet_quadratic_operator(M[0],n=9)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "6ba129d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'M,err,time_stats=conjugate_gradient_algorithm(args)'"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''M,err,time_stats=conjugate_gradient_algorithm(args)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46676792",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    args=cg_options()\n",
    "    if args.action==\"optimize\":\n",
    "        M,err,time_stats=conjugate_gradient_algorithm(args)\n",
    "    elif args.action==\"analysis\":\n",
    "        analysis(args)\n",
    "if __name__=='__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
