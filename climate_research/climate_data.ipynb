{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e843c627",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import os\n",
    "import argparse\n",
    "from datetime import date\n",
    "import json\n",
    "import copy\n",
    "import scipy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import ndimage\n",
    "\n",
    "def ismember_(a,b):\n",
    "    for a_ in b:\n",
    "        if a==a_:\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def physical_domains(domain_sel_id,validation=True):\n",
    "    partition={}\n",
    "    partition['train']={}\n",
    "    print('domain id: '+str(domain_sel_id))\n",
    "    if domain_sel_id==0:\n",
    "        partition['train']['xmin']=[-50,-180,-110,-48]\n",
    "        partition['train']['xmax']=[-20,-162,-92,-30]\n",
    "        partition['train']['ymin']=[35,-40,-20,0]\n",
    "        partition['train']['ymax']=[50,-25,-5,15]\n",
    "    elif domain_sel_id==1:\n",
    "        partition['train']['xmin']=[-47]#,-150,-117]\n",
    "        partition['train']['xmax']=[-38.7]#,-130,-97]\n",
    "        partition['train']['ymin']=[43]#,-50,-20]\n",
    "        partition['train']['ymax']=[48.7]#,-35,-5]  \n",
    "    elif domain_sel_id==2:\n",
    "        partition['train']['xmin']=[-150]\n",
    "        partition['train']['xmax']=[-130]\n",
    "        partition['train']['ymin']=[-50]\n",
    "        partition['train']['ymax']=[-35]\n",
    "    elif domain_sel_id==3:\n",
    "        partition['train']={\n",
    "        'xmin': [-1e3],'xmax':[1e3],\\\n",
    "        'ymin': [-1e3],'ymax':[1e3],\\\n",
    "        'tmin': 0,'tmax':1}\n",
    "        '''u=np.load('/scratch/cg3306/climate/physical_land_11.npy')\n",
    "        x=np.load('/scratch/cg3306/climate/physical_x.npy')\n",
    "        y=np.load('/scratch/cg3306/climate/physical_y.npy')\n",
    "        nx,ny=len(x),len(y)\n",
    "        spread=10\n",
    "        domlenx=15\n",
    "        domleny=5\n",
    "        yy=torch.linspace(0,ny,ny//domleny).to(torch.int).numpy().tolist()\n",
    "        xx=torch.linspace(0,nx,nx//domlenx).to(torch.int).numpy().tolist()\n",
    "        partition['train']['xmin']=[]\n",
    "        partition['train']['xmax']=[]\n",
    "        partition['train']['ymin']=[]\n",
    "        partition['train']['ymax']=[]\n",
    "        \n",
    "        m=1\n",
    "        landmass=np.zeros((len(yy)-1+2*m,len(xx)-1+2*m))\n",
    "        \n",
    "        for j in range(len(xx)-1):\n",
    "            for i in range(len(yy)-1):\n",
    "                j0=np.maximum(xx[j]-spread,0)\n",
    "                j1=np.minimum(xx[j+1]+spread,nx-1)\n",
    "                i0=np.maximum(yy[i]-spread,0)\n",
    "                i1=np.minimum(yy[i+1]+spread,ny-1)\n",
    "                landmass[i+m,j+m]=np.sum(u[i0:i1+1,j0:j1+1])>0\n",
    "        \n",
    "        for j in range(len(xx)-1):\n",
    "            for i in range(len(yy)-1):\n",
    "                j0=np.maximum(xx[j]-spread,0)\n",
    "                j1=np.minimum(xx[j+1]+spread,nx-1)\n",
    "                i0=np.maximum(yy[i]-spread,0)\n",
    "                i1=np.minimum(yy[i+1]+spread,ny-1)\n",
    "                #landmassflag=np.sum(u[i0:i1+1,j0:j1+1])\n",
    "                #totsize=(i1-i0)*(j1-j0)\n",
    "                landmassflag=np.sum(landmass[i:i+2*m,j:j+2*m])\n",
    "                if landmassflag==0:#landmass/totsize<0.1:\n",
    "                    partition['train']['xmin'].append(x[j0])\n",
    "                    partition['train']['xmax'].append(x[j1])\n",
    "                    partition['train']['ymin'].append(y[i0])\n",
    "                    partition['train']['ymax'].append(y[i1])'''\n",
    "    elif domain_sel_id==4:\n",
    "        u=np.load('/scratch/cg3306/climate/physical_land_11.npy')\n",
    "        x=np.load('/scratch/cg3306/climate/physical_x.npy')\n",
    "        y=np.load('/scratch/cg3306/climate/physical_y.npy')\n",
    "        nx,ny=len(x),len(y)\n",
    "        spread=10\n",
    "        domlen=20\n",
    "        yy=torch.linspace(0,ny,ny//domlen).to(torch.int).numpy().tolist()\n",
    "        xx=torch.linspace(0,nx,nx//domlen).to(torch.int).numpy().tolist()\n",
    "        partition['train']['xmin']=[]\n",
    "        partition['train']['xmax']=[]\n",
    "        partition['train']['ymin']=[]\n",
    "        partition['train']['ymax']=[]\n",
    "        \n",
    "        m=1\n",
    "        landmass=np.zeros((len(yy)-1+2*m,len(xx)-1+2*m))\n",
    "        \n",
    "        for j in range(len(xx)-1):\n",
    "            for i in range(len(yy)-1):\n",
    "                j0=np.maximum(xx[j]-spread,0)\n",
    "                j1=np.minimum(xx[j+1]+spread,nx-1)\n",
    "                i0=np.maximum(yy[i]-spread,0)\n",
    "                i1=np.minimum(yy[i+1]+spread,ny-1)\n",
    "                landmass[i+m,j+m]=np.sum(u[i0:i1+1,j0:j1+1])>0\n",
    "        \n",
    "        for j in range(len(xx)-1):\n",
    "            for i in range(len(yy)-1):\n",
    "                j0=np.maximum(xx[j]-spread,0)\n",
    "                j1=np.minimum(xx[j+1]+spread,nx-1)\n",
    "                i0=np.maximum(yy[i]-spread,0)\n",
    "                i1=np.minimum(yy[i+1]+spread,ny-1)\n",
    "                #landmassflag=np.sum(u[i0:i1+1,j0:j1+1])\n",
    "                #totsize=(i1-i0)*(j1-j0)\n",
    "                landmassflag=np.sum(landmass[i:i+2*m,j:j+2*m])\n",
    "                if landmassflag==0 and y[i0]>-25 and y[i1]<25:\n",
    "                    partition['train']['xmin'].append(x[j0])\n",
    "                    partition['train']['xmax'].append(x[j1])\n",
    "                    partition['train']['ymin'].append(y[i0])\n",
    "                    partition['train']['ymax'].append(y[i1])\n",
    "        \n",
    "                \n",
    "    partition['train']['tmin']=0.0\n",
    "    partition['train']['tmax']=0.7\n",
    "    if validation:\n",
    "        partition['validation']=copy.deepcopy(partition['train'])\n",
    "        partition['validation']['tmin']=0.75\n",
    "        partition['validation']['tmax']=0.8\n",
    "    else:\n",
    "        partition['train']['tmax']=0.8\n",
    "    partition['test']=copy.deepcopy(partition['train'])\n",
    "    partition['test']['tmin']=0.85\n",
    "    partition['test']['tmax']=1\n",
    "    \n",
    "    partition['earth']={\n",
    "        'xmin': [-1e3],'xmax':[1e3],\\\n",
    "        'ymin': [-1e3],'ymax':[1e3],\\\n",
    "        'tmin': 0.85,'tmax':1}\n",
    "    return partition\n",
    "\n",
    "def load_ds_zarr(args):\n",
    "    ds_zarr=xr.open_zarr(args.data_address)\n",
    "    tot_time=ds_zarr.time.shape[0]\n",
    "    \n",
    "    \n",
    "    if args.testrun>0:\n",
    "        sub_tot_time=args.testrun\n",
    "        rng = np.random.default_rng(0)\n",
    "        indices=np.sort(rng.choice(tot_time,size=sub_tot_time,replace=False))\n",
    "        ds_zarr=ds_zarr.sel(time=ds_zarr.time[indices].data)\n",
    "    '''usc=0\n",
    "    uss=0\n",
    "    M=20\n",
    "    give_sc=lambda AA: np.mean(np.abs(AA[AA==AA]))\n",
    "    for j in range(M):\n",
    "        dsi=ds_zarr.isel(time=np.arange(j,j+1))\n",
    "        u,v,S_x,S_y=dsi.usurf.values[0],dsi.vsurf.values[0],dsi.S_x.values[0],dsi.S_y.values[0]\n",
    "        u=np.stack([u,v],axis=0)\n",
    "        S=np.stack([S_x,S_y],axis=0)\n",
    "        usc+=give_sc(u)\n",
    "        uss+=give_sc(S)\n",
    "    usc=usc/M\n",
    "    uss=uss/M\n",
    "    \n",
    "    ds_zarr['usurf']=ds_zarr['usurf']/usc\n",
    "    ds_zarr['vsurf']=ds_zarr['vsurf']/usc\n",
    "    ds_zarr['S_x']=ds_zarr['S_x']/uss\n",
    "    ds_zarr['S_y']=ds_zarr['S_y']/uss\n",
    "    '''\n",
    "    return ds_zarr\n",
    "\n",
    "def get_land_masks(val_gen):\n",
    "    if isinstance(val_gen.dataset,GlobalDataset):\n",
    "        masks=val_gen.dataset.get_landmask()\n",
    "        return 1-masks\n",
    "    val_gen.dataset.no_more_mask_flag=False\n",
    "    ii=0\n",
    "    for local_batch,local_masks,local_labels in val_gen:\n",
    "        if ii==0:\n",
    "            bsize=local_batch.shape[0]\n",
    "            masks=torch.zeros((val_gen.dataset.num_domains//bsize + 1)*bsize,local_masks.shape[1],local_masks.shape[2],local_masks.shape[3])\n",
    "        masks[ii:ii+local_masks.shape[0]]=local_masks\n",
    "        ii+=local_masks.shape[0]\n",
    "        if ii>=val_gen.dataset.num_domains:\n",
    "            break\n",
    "    masks=masks[0:val_gen.dataset.num_domains]\n",
    "    val_gen.dataset.no_more_mask_flag=True\n",
    "    return masks\n",
    "\n",
    "\n",
    "def zigzag_freq(n,m,f0,df,d=1,reps=100):\n",
    "    x=np.linspace(0,m,n)\n",
    "    for _ in range(m):\n",
    "        x=np.abs(1-np.abs(1-x))\n",
    "    x=x**d*df+f0\n",
    "    x=np.cumsum(x)\n",
    "    x=x/x[-1]*2*np.pi*reps\n",
    "    return x\n",
    "\n",
    "def sigmoid_freq(n,f0,df,d=20,reps=100):\n",
    "    x=np.linspace(-1,1,n)\n",
    "    x=1/(1+np.exp(-x*d))\n",
    "    x=x*df+f0\n",
    "    x=np.cumsum(x)\n",
    "    x=x/x[-1]*2*np.pi*reps\n",
    "    return x\n",
    "def geographic_features(y,x):\n",
    "    lat1=zigzag_freq(len(y),2,(30*645)//len(y),40,d=1,reps=55)\n",
    "    lat2=sigmoid_freq(len(y), (30*645)//len(y),30,d=15,reps=55)\n",
    "    lng1=zigzag_freq(len(x),2,(30*645)//len(y),50,d=1,reps=70)\n",
    "    lng2=zigzag_freq(len(x),4,(30*645)//len(y),50,d=1,reps=70)\n",
    "    return lat1, lat2, lng1, lng2\n",
    "\n",
    "\n",
    "\n",
    "def hat_freq(n,span):\n",
    "    p0=1/2\n",
    "    p1=4\n",
    "    m=2\n",
    "    x=np.linspace(0,m,n)\n",
    "    for _ in range(m):\n",
    "        x=np.abs(1-np.abs(1-x))\n",
    "    Pmin=span*p0\n",
    "    Pmax=span*p1\n",
    "\n",
    "    Fmin=1/Pmax\n",
    "    Fmax=1/Pmin\n",
    "    dF=(Fmax-Fmin)\n",
    "    x=x*dF+Fmin\n",
    "    x=np.cumsum(x)\n",
    "    return x*2*np.pi\n",
    "\n",
    "def sigmoid_freq(n,span):\n",
    "    p0=1/2\n",
    "    p1=4\n",
    "    m=2\n",
    "    d=20\n",
    "    \n",
    "    x=np.linspace(-1,1,n)\n",
    "    x=1/(1+np.exp(-x*d))\n",
    "    \n",
    "    Pmin=span*p0\n",
    "    Pmax=span*p1\n",
    "\n",
    "    Fmin=1/Pmax\n",
    "    Fmax=1/Pmin\n",
    "    dF=(Fmax-Fmin)\n",
    "    \n",
    "    x=x*dF+Fmin\n",
    "    x=np.cumsum(x)\n",
    "    return x*2*np.pi\n",
    "def geographic_features2(n,span):\n",
    "    lat1=hat_freq(n,span)\n",
    "    lat2=sigmoid_freq(n,span)\n",
    "    lng1=lat1\n",
    "    lng2=lat2\n",
    "    return lat1, lat2, lng1, lng2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "332357ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset1(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, ds_data,domains,net,cropped=False,subtime=1,datatype=0,roundearth=False,readfile2=False):\n",
    "        #print('hereeeee')\n",
    "        self.spread=net.spread\n",
    "        self.latsig=net.latsig\n",
    "        self.direct_coord=net.direct_coord\n",
    "        timeshuffle=net.timeshuffle\n",
    "        self.longitude=net.longitude\n",
    "        self.latsign=net.latsign\n",
    "        self.scale_u=net.rescale[0]\n",
    "        self.scale_S=net.rescale[1]\n",
    "        self.readfile2=readfile2\n",
    "        self.ds_data = ds_data\n",
    "        self.domains=domains\n",
    "        self.cropped=cropped\n",
    "        self.datatype=datatype\n",
    "        \n",
    "        self.num_domains=len(self.domains['xmin'])\n",
    "        tot_time=self.ds_data.isel(xu_ocean=[0],yu_ocean=[0]).time.shape[0]\n",
    "        self.time_st=np.int64(np.floor(tot_time*self.domains['tmin']))\n",
    "        self.time_tr=np.int64(np.ceil(tot_time*self.domains['tmax']))\n",
    "        self.tot_time=self.time_tr-self.time_st\n",
    "        self.num_time=np.int64(np.ceil(self.tot_time*subtime))\n",
    "   \n",
    "        self.filename='/scratch/cg3306/climate/physical_land_'+str(len(self.ds_data.xu_ocean.values))+'.npy'\n",
    "\n",
    "        dimens=[]\n",
    "        '''\n",
    "        self.time_per_domain=[]\n",
    "        for nd in range(self.num_domains):\n",
    "            self.time_per_domain.append(\\\n",
    "                        np.sort(np.random.choice(self.tot_time,self.num_time))+self.time_st)\n",
    "        \n",
    "        if not timeshuffle:\n",
    "            for i in range(1,nd):\n",
    "                self.time_per_domain[i]=self.time_per_domain[0]'''\n",
    "            \n",
    "        for nd in range(self.num_domains):\n",
    "            datsel=self.ds_data.sel(time=self.ds_data.time[0].data,\\\n",
    "                                    xu_ocean=slice(self.domains['xmin'][nd], self.domains['xmax'][nd]),\\\n",
    "                                    yu_ocean=slice(self.domains['ymin'][nd], self.domains['ymax'][nd]))\n",
    "            dimens.append([datsel.yu_ocean.shape[0],datsel.xu_ocean.shape[0]])\n",
    "        dimens=torch.tensor(dimens)\n",
    "        self.dimens=torch.amax(dimens,dim=0)\n",
    "        coords=[]\n",
    "        icoords=[]\n",
    "        geo=[]\n",
    "        \n",
    "        y=self.ds_data.yu_ocean.values\n",
    "        x=self.ds_data.xu_ocean.values\n",
    "        \n",
    "        if not self.direct_coord:\n",
    "            lat1, lat2, lng1, lng2 = geographic_features(y,x)\n",
    "        else:\n",
    "            lat=y/y[-1]\n",
    "            lng=x/x[-1]\n",
    "        for nd in range(self.num_domains):\n",
    "            datsel=self.ds_data.sel(time=self.ds_data.time[0].data,\\\n",
    "                                    xu_ocean=slice(self.domains['xmin'][nd], self.domains['xmax'][nd]),\\\n",
    "                                    yu_ocean=slice(self.domains['ymin'][nd], self.domains['ymax'][nd]))\n",
    "            \n",
    "            xx=datsel.xu_ocean.values\n",
    "            yy=datsel.yu_ocean.values\n",
    "            \n",
    "            i0=np.argmin(np.abs(yy[0]-y))\n",
    "            i1=np.argmin(np.abs(yy[-1]-y))+1\n",
    "            \n",
    "            j0=np.argmin(np.abs(xx[0]-x))\n",
    "            j1=np.argmin(np.abs(xx[-1]-x))+1\n",
    "            \n",
    "            if not self.direct_coord:\n",
    "                locgeo = lat1[i0:i1], lat2[i0:i1], lng1[j0:j1], lng2[j0:j1]\n",
    "            else:\n",
    "                locgeo = lat[i0:i1], lng[j0:j1]\n",
    "            locgeo = [torch.tensor(ll,dtype=torch.float32) for ll in locgeo]\n",
    "            geo.append(locgeo)\n",
    "            \n",
    "            coords.append([yy,xx])\n",
    "            icoords.append([i0,i1,j0,j1])\n",
    "        \n",
    "        self.coords=coords\n",
    "        self.geo=geo\n",
    "        self.icoords=icoords\n",
    "        self.no_more_mask_flag=True\n",
    "        \n",
    "        self.pooler=nn.MaxPool2d(2*self.spread+1,stride=1)\n",
    "        \n",
    "        y,x=self.coords[0]\n",
    "        dy=y[1:]-y[:-1]\n",
    "        dx=x[1:]-x[:-1]\n",
    "\n",
    "        mdy=np.mean(dy)\n",
    "        mdx=np.mean(dx)\n",
    "\n",
    "        self.box_km=[mdy*111,mdx*85]\n",
    "        \n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.num_domains*self.num_time\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #return torch.randn(1,10,10),torch.randn(1,10,10),torch.randn(1,10,10)\n",
    "        'Generates one sample of data'\n",
    "        spread=self.spread\n",
    "        usc=self.scale_u\n",
    "        ssc=self.scale_S\n",
    "        \n",
    "        nd=index%self.num_domains\n",
    "        nt=np.int64(np.floor(index/self.num_domains))+self.time_st\n",
    "        #nt=self.time_per_domain[nd][nt]\n",
    "        datsel=self.ds_data.isel(time=[nt]).\\\n",
    "                                sel(xu_ocean=slice(self.domains['xmin'][nd], self.domains['xmax'][nd]),\\\n",
    "                                yu_ocean=slice(self.domains['ymin'][nd], self.domains['ymax'][nd]))\n",
    "\n",
    "        usurf=datsel.usurf.values\n",
    "        vsurf=datsel.vsurf.values\n",
    "\n",
    "        usurf=torch.tensor(usurf,dtype=torch.float32)\n",
    "        vsurf=torch.tensor(vsurf,dtype=torch.float32)\n",
    "\n",
    "        #if resc:\n",
    "        usurf=usurf/usc\n",
    "        vsurf=vsurf/usc\n",
    "        \n",
    "        \n",
    "        if not (self.latsig or self.latsign or self.direct_coord):\n",
    "            X=torch.cat([usurf,vsurf],dim=0)\n",
    "        else:\n",
    "            locgeo=self.geo[nd]\n",
    "            xx=torch.ones(usurf.shape)\n",
    "            if not self.direct_coord:\n",
    "                wt=0\n",
    "                latcod=torch.cos(locgeo[0]+nt*wt*2*np.pi)\n",
    "                lat1=latcod.view(1,-1,1)*xx\n",
    "                \n",
    "                latcod=torch.cos(locgeo[1]+nt*wt*2*np.pi)\n",
    "                lat2=latcod.view(1,-1,1)*xx\n",
    "                \n",
    "                if self.longitude:\n",
    "                    latcod=torch.cos(locgeo[2]+nt*wt*2*np.pi)\n",
    "                    lng1=xx*latcod.view(1,1,-1)\n",
    "                    latcod=torch.cos(locgeo[3]+nt*wt*2*np.pi)\n",
    "                    lng2=xx*latcod.view(1,1,-1)\n",
    "                    X=torch.cat([usurf,vsurf,lat1,lat2,lng1,lng2],dim=0)\n",
    "                else:\n",
    "                    if self.latsign:\n",
    "                        X=torch.cat([usurf,vsurf,lat1,lat2],dim=0)\n",
    "                    else:\n",
    "                        X=torch.cat([usurf,vsurf,lat1],dim=0)\n",
    "            else:\n",
    "                '''latcod=locgeo[0]\n",
    "                lat=latcod.view(1,-1,1)*xx\n",
    "                latcod=locgeo[1]\n",
    "                lng=latcod.view(1,1,-1)*xx'''\n",
    "                x=datsel.xu_ocean.values\n",
    "                y=datsel.yu_ocean.values\n",
    "                dy=np.zeros((len(y),))\n",
    "                dy[1:]=y[1:]-y[:-1]\n",
    "                dy[:-1]=dy[:-1]+dy[1:]\n",
    "                dy[1:-1]=dy[1:-1]/2\n",
    "                dy=(dy-np.mean(dy))/np.std(dy)\n",
    "                cosx=np.cos(x/180*np.pi)\n",
    "                siny=np.sin(y/80*np.pi)\n",
    "\n",
    "                cosx=torch.reshape(torch.tensor(cosx,dtype=torch.float32),[1,1,-1])\n",
    "                siny=torch.reshape(torch.tensor(siny,dtype=torch.float32),[1,-1,1])\n",
    "                dy=torch.reshape(torch.tensor(dy,dtype=torch.float32),[1,-1,1])\n",
    "                fcosx=cosx+siny*0\n",
    "                fsiny=cosx*0+siny\n",
    "                fdy=cosx*0+dy\n",
    "                if self.longitude:\n",
    "                    X=torch.cat([usurf,vsurf,fcosx,fsiny,fdy],dim=0)\n",
    "                else:\n",
    "                    X=torch.cat([usurf,vsurf,fsiny,fdy],dim=0)\n",
    "        \n",
    "        sx=datsel.S_x[0,spread:-spread,spread:-spread].values\n",
    "        sy=datsel.S_y[0,spread:-spread,spread:-spread].values\n",
    "        sx=torch.tensor(sx,dtype=torch.float32)\n",
    "        sy=torch.tensor(sy,dtype=torch.float32)\n",
    "\n",
    "\n",
    "        sx=sx/self.scale_S\n",
    "        sy=sy/self.scale_S\n",
    "\n",
    "        Y=torch.stack([sx,sy],dim=0)\n",
    "        \n",
    "            \n",
    "        if not self.no_more_mask_flag:\n",
    "            if self.readfile2:\n",
    "                u=np.load(self.filename)\n",
    "            else:\n",
    "                u=np.load('/scratch/cg3306/climate/physical_land_11.npy')\n",
    "            i0,i1,j0,j1=self.icoords[nd]\n",
    "            M=torch.tensor(u[i0:i1,j0:j1],dtype=torch.float32)\n",
    "            #M=torch.zeros(X.shape[0],X.shape[1],X.shape[2])\n",
    "            #M[X!=X]=1\n",
    "            #M=torch.stack([M],dim=1)\n",
    "            M=torch.stack([M],dim=0)\n",
    "            M=torch.stack([M],dim=0)\n",
    "            M=self.pooler(M)\n",
    "            M=1-M[0]\n",
    "            \n",
    "        \n",
    "        Y[Y!=Y]=0\n",
    "        X[X!=X]=0\n",
    "        \n",
    "        '''X[0:2]=X[0:2]*10.\n",
    "        Y=Y*1.e7'''\n",
    "        \n",
    "        if not self.cropped:\n",
    "            p3d = (0, self.dimens[1]-2*spread-Y.shape[2], 0, self.dimens[0]-2*spread-Y.shape[1]) \n",
    "            Y = F.pad(Y, p3d, \"constant\", 0)\n",
    "            \n",
    "            if not self.no_more_mask_flag:\n",
    "                p3d = (0, self.dimens[1]-2*spread-M.shape[2], 0, self.dimens[0]-2*spread-M.shape[1]) \n",
    "                M = F.pad(M, p3d, \"constant\", 0)\n",
    "            \n",
    "            p3d = (0, self.dimens[1]-X.shape[2], 0, self.dimens[0]-X.shape[1]) \n",
    "            X = F.pad(X, p3d, \"constant\", 0)\n",
    "        if not self.no_more_mask_flag:\n",
    "            return X,M,Y\n",
    "        else:\n",
    "            return X,torch.tensor(nd),Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5bfeaf4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset():\n",
    "    data_info={}\n",
    "    lookupfile='/scratch/cg3306/climate/climate_research/model_data_info.json'\n",
    "    with open(lookupfile,'w') as infile:\n",
    "        json.dump(data_info,infile)\n",
    "        \n",
    "def safe():\n",
    "    lookupfile='/scratch/cg3306/climate/climate_research/model_data_info.json'\n",
    "    with open(lookupfile) as infile:\n",
    "        data_info=json.load(infile)\n",
    "    \n",
    "    lookupfile='/scratch/cg3306/climate/climate_research/model_data_info_2.json'\n",
    "    with open(lookupfile,'w') as infile:\n",
    "        json.dump(data_info,infile)\n",
    "def recover():\n",
    "    lookupfile='/scratch/cg3306/climate/climate_research/model_data_info_2.json'\n",
    "    random_wait()\n",
    "    with open(lookupfile) as infile:\n",
    "        data_info=json.load(infile)\n",
    "    \n",
    "    lookupfile='/scratch/cg3306/climate/climate_research/model_data_info.json'\n",
    "    random_wait()\n",
    "    with open(lookupfile,'w') as infile:\n",
    "        json.dump(data_info,infile)\n",
    "        \n",
    "def get_dict(model_bank_id,model_id,parallel=True):\n",
    "    expand_dict(model_bank_id,model_id)\n",
    "    lookupfile='/scratch/cg3306/climate/climate_research/model_data_info.json'\n",
    "    random_wait(parallel=parallel)\n",
    "    with open(lookupfile) as infile:\n",
    "        data_info_=json.load(infile)\n",
    "    return data_info_[str(model_bank_id)][str(model_id)]\n",
    "def expand_dict(model_bank_id,model_id,parallel=True):\n",
    "    lookupfile='/scratch/cg3306/climate/climate_research/model_data_info.json'\n",
    "    random_wait(parallel=parallel)\n",
    "    with open(lookupfile) as infile:\n",
    "        data_info_=json.load(infile)\n",
    "    iskey1=False\n",
    "    iskey2=False\n",
    "    if ismember_(str(model_bank_id),list(data_info_.keys()),):\n",
    "        iskey1=True\n",
    "        if ismember_(str(model_id),list(data_info_[str(model_bank_id)].keys())):\n",
    "            iskey2=True\n",
    "            \n",
    "    #print('expansion report: '+str(iskey1)+'  '+str(iskey2))\n",
    "    if not iskey1:\n",
    "        data_info_[str(model_bank_id)]={}\n",
    "    if not iskey2:\n",
    "        data_info_[str(model_bank_id)][str(model_id)]={}\n",
    "    random_wait(parallel=parallel)\n",
    "    with open(lookupfile,'w') as infile:\n",
    "        json.dump(data_info_,infile)\n",
    "def update_model_info(data_info,model_bank_id,model_id,parallel=True):\n",
    "    expand_dict(model_bank_id,model_id)\n",
    "    lookupfile='/scratch/cg3306/climate/climate_research/model_data_info.json'\n",
    "    random_wait(parallel=parallel)\n",
    "    with open(lookupfile) as infile:\n",
    "        data_info_=json.load(infile)\n",
    "    data_info_[str(model_bank_id)][str(model_id)]=data_info.copy()\n",
    "    random_wait(parallel=parallel)\n",
    "    with open(lookupfile,'w') as infile:\n",
    "        json.dump(data_info_,infile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8903d380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_wait(secs=2,parallel=True):\n",
    "    tt=np.random.rand()*5\n",
    "    time.sleep(tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b355a848",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-42b690c98ead>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mDataset2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m'Characterizes a dataset for PyTorch'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mds_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdomains\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_bank_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msubtime\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mheteroscrescale\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mparallel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdepthind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mlookupfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/scratch/cg3306/climate/climate_research/model_data_info.json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlookupfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlookupfile\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "class Dataset2(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self,ds_data,domains,model_id,model_bank_id,net,\\\n",
    "                 subtime=1,heteroscrescale=1,parallel=True,depthind=2):\n",
    "        lookupfile='/scratch/cg3306/climate/climate_research/model_data_info.json'\n",
    "        self.lookupfile=lookupfile\n",
    "        random_wait(parallel=parallel)\n",
    "        with open(lookupfile) as infile:\n",
    "            data_info_=json.load(infile)\n",
    "        data_info_=self.expand_(data_info_,model_bank_id,model_id).copy()\n",
    "        data_info=data_info_[str(model_bank_id)][str(model_id)].copy()\n",
    "        self.depthind=depthind\n",
    "        depthvals=[]\n",
    "        if 'st_ocean' in list(ds_data.coords.keys()):\n",
    "#             depth values are\n",
    "#             [   5.03355 ,   55.853249,  110.096153,  181.312454,  330.007751,\n",
    "#                       1497.56189 , 3508.633057]\n",
    "            depthvals=ds_data.coords['st_ocean'].values\n",
    "        if hasattr(net, 'skipcons'):\n",
    "            self.padded=net.skipcons\n",
    "        else:\n",
    "            self.padded=False\n",
    "        self.depthvals=depthvals\n",
    "        self.spread=net.spread\n",
    "        data_info['spread']=int(net.spread)\n",
    "        \n",
    "        self.freq_coord=net.freq_coord\n",
    "        data_info['freq_coord']=self.freq_coord\n",
    "        \n",
    "        self.direct_coord=net.direct_coord\n",
    "        data_info['direct_coord']=self.direct_coord\n",
    "        \n",
    "        self.heteroscrescale=heteroscrescale\n",
    "        \n",
    "        self.longitude=net.longitude\n",
    "        self.latsign=net.latsign\n",
    "        self.latsig=net.latsig\n",
    "        \n",
    "        self.ds_data = ds_data.sel(yu_ocean=slice(-85, 85))\n",
    "        self.domains=domains\n",
    "        \n",
    "            \n",
    "        if ismember_('inscales',list(data_info.keys())):\n",
    "            self.inscales=data_info['inscales']\n",
    "            self.outscales=data_info['outscales']\n",
    "        else:\n",
    "            self.inscales=[]\n",
    "            self.outscales=[]\n",
    "\n",
    "        self.inputs=data_info['inputs']\n",
    "        self.outputs=data_info['outputs']\n",
    "        self.parallel=parallel\n",
    "        self.num_domains=len(self.domains['xmin'])\n",
    "        tot_time=self.ds_data.isel(xu_ocean=[0],yu_ocean=[0]).time.shape[0]\n",
    "        self.time_st=np.int64(np.floor(tot_time*self.domains['tmin']))\n",
    "        self.time_tr=np.int64(np.ceil(tot_time*self.domains['tmax']))\n",
    "        self.tot_time=self.time_tr-self.time_st\n",
    "        self.num_time=np.int64(np.ceil(self.tot_time*subtime))\n",
    "        \n",
    "        self.model_bank_id=model_bank_id\n",
    "        self.model_id=model_id\n",
    "        self.filename=data_info['maskloc']\n",
    "        \n",
    "        dimens=[]\n",
    "        for nd in range(self.num_domains):\n",
    "            datsel=self.ds_data.sel(time=self.ds_data.time[0].data,\\\n",
    "                                    xu_ocean=slice(self.domains['xmin'][nd], self.domains['xmax'][nd]),\\\n",
    "                                    yu_ocean=slice(self.domains['ymin'][nd], self.domains['ymax'][nd]))\n",
    "            dimens.append([datsel.yu_ocean.shape[0],datsel.xu_ocean.shape[0]])\n",
    "        dimens=torch.tensor(dimens)\n",
    "        self.dimens=torch.amax(dimens,dim=0)\n",
    "        self.glbl_data=self.ds_data.yu_ocean.shape[0]*self.ds_data.xu_ocean.shape[0]==self.dimens[0]*self.dimens[1]\n",
    "        if self.glbl_data:\n",
    "            self.dimens[1]+=self.spread*2\n",
    "        coords=[]\n",
    "        icoords=[]\n",
    "        geo=[]\n",
    "        \n",
    "        y=self.ds_data.yu_ocean.values\n",
    "        x=self.ds_data.xu_ocean.values\n",
    "        \n",
    "        if not self.direct_coord:\n",
    "            #lat1, lat2, lng1, lng2 = geographic_features(y,x)\n",
    "            lat1, lat2, lng1, lng2 = geographic_features2(len(y),net.spread*2+1)\n",
    "        else:\n",
    "            lat=y/y[-1]\n",
    "            lng=x/x[-1]\n",
    "        for nd in range(self.num_domains):\n",
    "            datsel=self.ds_data.sel(time=self.ds_data.time[0].data,\\\n",
    "                                    xu_ocean=slice(self.domains['xmin'][nd], self.domains['xmax'][nd]),\\\n",
    "                                    yu_ocean=slice(self.domains['ymin'][nd], self.domains['ymax'][nd]))\n",
    "            \n",
    "            xx=datsel.xu_ocean.values\n",
    "            yy=datsel.yu_ocean.values\n",
    "            \n",
    "            i0=np.argmin(np.abs(yy[0]-y))\n",
    "            i1=np.argmin(np.abs(yy[-1]-y))+1\n",
    "            \n",
    "            j0=np.argmin(np.abs(xx[0]-x))\n",
    "            j1=np.argmin(np.abs(xx[-1]-x))+1\n",
    "            \n",
    "            if not self.direct_coord:\n",
    "                locgeo = lat1[i0:i1], lat2[i0:i1], lng1[j0:j1], lng2[j0:j1]\n",
    "            else:\n",
    "                locgeo = lat[i0:i1], lng[j0:j1]\n",
    "            locgeo = [torch.tensor(ll,dtype=torch.float32) for ll in locgeo]\n",
    "            geo.append(locgeo)\n",
    "            \n",
    "            coords.append([yy,xx])\n",
    "            icoords.append([i0,i1,j0,j1])\n",
    "        \n",
    "        self.coords=coords\n",
    "        self.geo=geo\n",
    "        self.icoords=icoords\n",
    "        self.no_more_mask_flag=True\n",
    "        \n",
    "        if not net.gan:\n",
    "            self.mask_spread=net.spread\n",
    "        else:\n",
    "            self.mask_spread=(net.receptive_field-1)//2\n",
    "        \n",
    "        self.pooler=nn.MaxPool2d(2*self.mask_spread+1,stride=1)\n",
    "        \n",
    "        y,x=self.coords[0]\n",
    "        dy=y[1:]-y[:-1]\n",
    "        dx=x[1:]-x[:-1]\n",
    "\n",
    "        mdy=np.mean(dy)\n",
    "        mdx=np.mean(dx)\n",
    "\n",
    "        self.box_km=[mdy*111,mdx*85]\n",
    "        \n",
    "        #self.save_info_file(data_info)\n",
    "        self.data_info=data_info.copy()\n",
    "    def expand_(self,data_info_,model_bank_id,model_id):\n",
    "        sufficient_len=False\n",
    "        if ismember_(str(model_bank_id),list(data_info_.keys())):\n",
    "            if ismember_(str(model_id),list(data_info_[str(model_bank_id)].keys())):\n",
    "                sufficient_len=True\n",
    "        if not sufficient_len:\n",
    "            #print('expand_ resets')\n",
    "            data_info_[str(model_bank_id)][str(model_bank)]=data_info_[str(model_bank_id)]['0'].copy()\n",
    "        return data_info_\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.num_domains*self.num_time\n",
    "    def get_info_file(self):\n",
    "        with open(self.lookupfile) as infile:\n",
    "            data_info=json.load(infile)\n",
    "        return data_info[str(self.model_bank_id)][str(self.model_id)].copy()\n",
    "    def save_info_file(self,data_info):\n",
    "        random_wait(parallel=self.parallel)\n",
    "        with open(self.lookupfile) as infile:\n",
    "            data_info_=json.load(infile)\n",
    "        data_info_[str(self.model_bank_id)][str(self.model_id)]=data_info.copy()\n",
    "        with open(self.lookupfile,'w') as infile:\n",
    "            json.dump(data_info_,infile)\n",
    "    def save_masks(self,tag=''):\n",
    "        Ms=[[] for nd in range(len(self.icoords))]\n",
    "        for nd in range(len(self.icoords)):\n",
    "            if self.glbl_data:\n",
    "                X,Y=self.input_output(nd,scale=False,crop=True,periodic_lon_expand=True)\n",
    "            else:\n",
    "                X,Y=self.input_output(nd,scale=False,crop=True)\n",
    "            #X,_=self.input_output(nd)\n",
    "            u=X[0]\n",
    "            u[u==0]=np.nan\n",
    "            u[u==u]=0\n",
    "            u[u!=u]=1\n",
    "            M=u.clone().detach().type(torch.float)\n",
    "            \n",
    "            M=torch.stack([M],dim=0)\n",
    "            \n",
    "            M=torch.stack([M],dim=0)\n",
    "            \n",
    "            M=self.pooler(M)\n",
    "            M=1-M[0]\n",
    "            if self.padded:\n",
    "                shp=list(M.numpy().shape)\n",
    "                shp[1]+=2*self.spread\n",
    "                shp[2]+=2*self.spread\n",
    "                Z=torch.zeros(shp)\n",
    "                Z[:,self.spread:-self.spread,self.spread:-self.spread]=M\n",
    "                Ms[nd]=self.pad_with_zero(Z,0)\n",
    "            else:\n",
    "                Ms[nd]=self.pad_with_zero(M,self.mask_spread)\n",
    "        \n",
    "        Ms=torch.stack(Ms).detach().numpy()\n",
    "        data_info=self.get_info_file()\n",
    "        filename=data_info['maskloc'+tag]\n",
    "        with open(filename, 'wb') as f:\n",
    "            np.save(f, Ms)\n",
    "    def get_masks(self,glbl=False,padded=False):\n",
    "        data_info=self.get_info_file()\n",
    "        model_bank_id=self.model_bank_id\n",
    "        model_id=self.model_id\n",
    "        filename=data_info['maskloc']\n",
    "        if glbl:\n",
    "            filename=filename.replace('dom4','glbl')\n",
    "        if padded:\n",
    "            if not 'padded' in filename:\n",
    "                filename=filename.replace('.npy','-padded.npy')\n",
    "        M=np.load(filename)\n",
    "        M=torch.tensor(M,dtype=torch.float32)\n",
    "        M.requires_grad=False\n",
    "        return M\n",
    "    def get_mask_address(self,):\n",
    "        data_info=self.get_info_file()\n",
    "        model_bank_id=self.model_bank_id\n",
    "        model_id=self.model_id\n",
    "        filename=data_info['maskloc']\n",
    "        return filename\n",
    "    def compute_scales(self):\n",
    "        data_info=self.get_info_file()\n",
    "        Ms=[]\n",
    "        innum=len(self.inputs)\n",
    "        outnum=len(self.outputs)\n",
    "        inscales=torch.zeros(innum)\n",
    "        outscales=torch.zeros(outnum)\n",
    "        M=50\n",
    "        for nd in range(M):\n",
    "            if self.glbl_data:\n",
    "                X,Y=self.input_output(nd,scale=False,crop=True,periodic_lon_expand=True)\n",
    "            else:\n",
    "                X,Y=self.input_output(nd,scale=False,crop=True)\n",
    "            u=X[0]\n",
    "            y=Y[0]\n",
    "            u[u==0]=np.nan\n",
    "            y[y==0]=np.nan\n",
    "            inscales+=torch.mean(torch.abs(X[:innum,u==u]),dim=(1))/M\n",
    "            outscales+=torch.mean(torch.abs(Y[:outnum,y==y]),dim=(1))/M\n",
    "        inscales,outscales=inscales.numpy(),outscales.numpy()\n",
    "        return inscales,outscales\n",
    "    def save_scales(self):\n",
    "        data_info=self.get_info_file()\n",
    "        Ms=[]\n",
    "        innum=len(self.inputs)\n",
    "        outnum=len(self.outputs)\n",
    "        inscales=torch.zeros(innum)\n",
    "        outscales=torch.zeros(outnum)\n",
    "        M=50\n",
    "        for nd in range(M):\n",
    "            if self.glbl_data:\n",
    "                X,Y=self.input_output(nd,scale=False,crop=True,periodic_lon_expand=True)\n",
    "            else:\n",
    "                X,Y=self.input_output(nd,scale=False,crop=True)\n",
    "            #X,Y=self.input_output(nd,periodic_lon_expand=True)\n",
    "            u=X[0]\n",
    "            y=Y[0]\n",
    "            u[u==0]=np.nan\n",
    "            y[y==0]=np.nan\n",
    "            inscales+=torch.mean(torch.abs(X[:innum,u==u]),dim=(1))/M\n",
    "            outscales+=torch.mean(torch.abs(Y[:outnum,y==y]),dim=(1))/M\n",
    "        inscales,outscales=inscales.numpy(),outscales.numpy()\n",
    "        \n",
    "        model_bank_id=self.model_bank_id\n",
    "        model_id=self.model_id\n",
    "        data_info['inscales']=inscales.tolist()\n",
    "        data_info['outscales']=outscales.tolist()\n",
    "        self.inscales=inscales\n",
    "        self.outscales=outscales\n",
    "        self.save_info_file(data_info)\n",
    "    def domain_index(self,index):\n",
    "        return index%self.num_domains\n",
    "    def input_output(self,index,scale=True,crop=True,periodic_lon_expand=False):\n",
    "        'Generates one sample of data'\n",
    "        spread=self.spread\n",
    "        nd=index%self.num_domains\n",
    "        nt=np.int64(np.floor(index/self.num_domains))+self.time_st\n",
    "        #nt=self.time_per_domain[nd][nt]\n",
    "        datsel=self.ds_data\n",
    "        if 'st_ocean' in list(self.ds_data.coords.keys()):\n",
    "            datsel=datsel.isel(st_ocean=self.depthind)\n",
    "        datsel=datsel.isel(time=[nt]).\\\n",
    "                                sel(xu_ocean=slice(self.domains['xmin'][nd], self.domains['xmax'][nd]),\\\n",
    "                                yu_ocean=slice(self.domains['ymin'][nd], self.domains['ymax'][nd]))\n",
    "        if 'st_ocean' in self.data_info:\n",
    "            datsel=datsel.isel(st_ocean=self.data_info['st_ocean']).sum(dim='st_ocean')\n",
    "        \n",
    "        X=[datsel[self.inputs[i]].values for i in range(len(self.inputs))]\n",
    "        if self.spread>0 and crop and not self.padded:\n",
    "            Y=[datsel[self.outputs[i]].values\\\n",
    "                       [:,self.spread:-self.spread,:]\\\n",
    "                       for i in range(len(self.outputs))]\n",
    "            if not periodic_lon_expand:\n",
    "                Y=[Y[i][:,:,self.spread:-self.spread]\\\n",
    "                       for i in range(len(self.outputs))]\n",
    "        else:\n",
    "            Y=[datsel[self.outputs[i]].values\\\n",
    "                          for i in range(len(self.outputs))]\n",
    "        \n",
    "        if scale:\n",
    "            X=[X[i]/self.inscales[i] for i in range(len(self.inputs))]\n",
    "            Y=[Y[i]/self.outscales[i]/self.heteroscrescale for i in range(len(self.outputs))]\n",
    "        \n",
    "        usurf=datsel.usurf.values\n",
    "        vsurf=datsel.vsurf.values\n",
    "        X=[torch.tensor(x,dtype=torch.float32) for x in X]\n",
    "        Y=[torch.tensor(y,dtype=torch.float32) for y in Y]\n",
    "        \n",
    "        X=torch.cat(X,dim=0)\n",
    "        Y=torch.cat(Y,dim=0)\n",
    "        if self.freq_coord or self.direct_coord:\n",
    "            locgeo=self.geo[nd]\n",
    "            xx=torch.ones(X[0].shape)\n",
    "            if not self.direct_coord:\n",
    "                wt=0\n",
    "                latcod=torch.cos(locgeo[0]+nt*wt*2*np.pi)\n",
    "                lat1=latcod.view(1,-1,1)*xx\n",
    "                \n",
    "                latcod=torch.cos(locgeo[1]+nt*wt*2*np.pi)\n",
    "                lat2=latcod.view(1,-1,1)*xx\n",
    "                '''latcod=torch.cos(locgeo[2]+nt*wt*2*np.pi)\n",
    "                lng1=xx*latcod.view(1,1,-1)\n",
    "                latcod=torch.cos(locgeo[3]+nt*wt*2*np.pi)\n",
    "                lng2=xx*latcod.view(1,1,-1)'''\n",
    "                if self.latsign:\n",
    "                    X=torch.cat([X,lat1],dim=0)\n",
    "                if self.latsig:\n",
    "                    X=torch.cat([X,lat2],dim=0)\n",
    "                if self.longitude:\n",
    "                    X=torch.cat([X,lng1,lng2],dim=0)\n",
    "               \n",
    "            else:\n",
    "                x=datsel.xu_ocean.values\n",
    "                y=datsel.yu_ocean.values\n",
    "                dy=np.zeros((len(y),))\n",
    "                dy[1:]=y[1:]-y[:-1]\n",
    "                dy[:-1]=dy[:-1]+dy[1:]\n",
    "                dy[1:-1]=dy[1:-1]/2\n",
    "                dy=(dy-np.mean(dy))/np.std(dy)\n",
    "                cosx=np.cos(x/180*np.pi)\n",
    "                siny=np.sin(y/80*np.pi)\n",
    "\n",
    "                cosx=torch.reshape(torch.tensor(cosx,dtype=torch.float32),[1,1,-1])\n",
    "                siny=torch.reshape(torch.tensor(siny,dtype=torch.float32),[1,-1,1])\n",
    "                dy=torch.reshape(torch.tensor(dy,dtype=torch.float32),[1,-1,1])\n",
    "                fcosx=cosx+siny*0\n",
    "                fsiny=cosx*0+siny\n",
    "                fdy=cosx*0+dy\n",
    "                if self.latsign:\n",
    "                    X=torch.cat([X,fsiny],dim=0)\n",
    "                if self.latsig:\n",
    "                    X=torch.cat([X,fdy],dim=0)\n",
    "                if self.longitude:\n",
    "                    X=torch.cat([X,fcosx],dim=0)\n",
    "        if self.spread>0 and periodic_lon_expand:\n",
    "            X=torch.cat([X[:,:,-self.spread:],X,X[:,:,:self.spread]], axis=2)\n",
    "            if self.padded:\n",
    "                Y=torch.cat([Y[:,:,-self.spread:],Y,Y[:,:,:self.spread]], axis=2)\n",
    "        return X,Y\n",
    "    def __getitem__(self, index):      \n",
    "        if self.glbl_data:\n",
    "            X,Y=self.input_output(index,crop=True,periodic_lon_expand=True)\n",
    "        else:\n",
    "            X,Y=self.input_output(index,crop=True)\n",
    "        Y[Y!=Y]=0\n",
    "        X[X!=X]=0\n",
    "        if not self.padded:\n",
    "            X,Y=self.pad_with_zero(X,0),self.pad_with_zero(Y,self.spread)\n",
    "        else:\n",
    "            X,Y=self.pad_with_zero(X,0),self.pad_with_zero(Y,0)\n",
    "        return X,torch.tensor(self.domain_index(index)),Y\n",
    "    def pad_with_zero(self,Y,spread,padding_val=0,centered=False):\n",
    "        #p3d = (0, self.dimens[1]-2*spread-Y.shape[2], 0, self.dimens[0]-2*spread-Y.shape[1]) \n",
    "        if not centered:\n",
    "            p3d = (0, self.dimens[1]-2*spread-Y.shape[2], 0, self.dimens[0]-2*spread-Y.shape[1]) \n",
    "        else:\n",
    "            d1=self.dimens[1]-2*spread-Y.shape[2]\n",
    "            d2=self.dimens[0]-2*spread-Y.shape[1]\n",
    "            p3d = (d1//2,d1-d1//2 , d2//2, d2-d2//2) \n",
    "        Y = F.pad(Y, p3d, \"constant\", padding_val)\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d83952b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subeddy_forcing(ds_zarr,sigma,t,informative=False):\n",
    "    x=ds_zarr.xu_ocean.values\n",
    "    y=ds_zarr.yu_ocean.values\n",
    "    x_=x[1:-1]\n",
    "    y_=y[1:-1]\n",
    "    x_=x_[::sigma]\n",
    "    y_=y_[::sigma]\n",
    "    if informative:\n",
    "        return x_,y_\n",
    "    dx=x[2:]-x[:-2]\n",
    "    dy=y[2:]-y[:-2]\n",
    "    dy=np.reshape(dy,[-1,1])\n",
    "    dx=np.reshape(dx,[1,-1])\n",
    "    dxy=dx*dy\n",
    "    #x=np.reshape(x,[1,-1])\n",
    "    #y=np.reshape(y,[-1,1])\n",
    "\n",
    "    u=ds_zarr.isel(time=np.arange(t,t+1)).usurf.values[0]\n",
    "    v=ds_zarr.isel(time=np.arange(t,t+1)).vsurf.values[0]\n",
    "\n",
    "    a=np.zeros((4*sigma+1,4*sigma+1))\n",
    "    for i in range(-2*sigma,2*sigma+1):\n",
    "        for j in range(-2*sigma,2*sigma+1):\n",
    "            a[i+sigma,j+sigma]=np.exp( - (i**2+j**2)/(sigma/2)**2/2)\n",
    "    a=a/np.sum(a)\n",
    "\n",
    "    A=np.stack([a],axis=0)\n",
    "\n",
    "    adxy=ndimage.convolve(dxy, a, mode='mirror')\n",
    "\n",
    "    adxy=np.stack([adxy],axis=0)\n",
    "    dudy=(u[2:,1:-1]-u[:-2,1:-1])/dy\n",
    "    dudx=(u[1:-1,2:]-u[1:-1,2:])/dx\n",
    "    dvdy=(v[2:,1:-1]-v[:-2,1:-1])/dy\n",
    "    dvdx=(v[1:-1,2:]-v[1:-1,2:])/dx\n",
    "    u,v=u[1:-1,1:-1],v[1:-1,1:-1]\n",
    "    U=np.stack((u,v,dudx,dudy,dvdx,dvdy),axis=0)\n",
    "\n",
    "    S=np.stack([U[0]*U[2]+U[1]*U[3],U[0]*U[4]+U[1]*U[5]],axis=0)\n",
    "    U=ndimage.convolve(U, A, mode='mirror')/adxy\n",
    "    S=ndimage.convolve(S, A, mode='mirror')/adxy\n",
    "    S=S[:,::sigma,::sigma]\n",
    "    U=U[:,::sigma,::sigma]\n",
    "    S=S-np.stack([U[0]*U[2]+U[1]*U[3],U[0]*U[4]+U[1]*U[5]],axis=0)\n",
    "    U=U[:2]\n",
    "    return U,S\n",
    "\n",
    "'''\n",
    "def geographic_features2(y,x):\n",
    "    lat1=zigzag_freq(len(y),2,30,40,d=1,reps=np.int(len(y)/650*55))\n",
    "    lat2=sigmoid_freq(len(y),30,30,d=15,reps=np.int(len(y)/650*55))\n",
    "    lng1=zigzag_freq(len(x),2,30,50,d=1,reps=np.int(len(x)/900*70))\n",
    "    lng2=zigzag_freq(len(x),4,30,50,d=1,reps=np.int(len(x)/900*70))\n",
    "    return lat1, lat2, lng1, lng2\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "class GlobalDataset(torch.utils.data.Dataset):\n",
    "    'Characterizes a dataset for PyTorch'\n",
    "    def __init__(self, ds_data,domains,ypad=75,xpad=300,subtime=1):\n",
    "        self.ds_data = ds_data\n",
    "        self.domains=domains\n",
    "        self.xpad=xpad\n",
    "        self.ypad=ypad\n",
    "        tot_time=self.ds_data.isel(xu_ocean=[0],yu_ocean=[0]).time.shape[0]\n",
    "        self.time_st=np.int64(np.floor(tot_time*self.domains['tmin']))\n",
    "        self.time_tr=np.int64(np.ceil(tot_time*self.domains['tmax']))\n",
    "        self.tot_time=self.time_tr-self.time_st\n",
    "        self.num_time=np.int64(np.ceil(self.tot_time*subtime))\n",
    "        self.time_downsample=np.sort(np.random.choice(\\\n",
    "                                        self.tot_time,self.num_time,replace=False))+self.time_st\n",
    "    def __len__(self):\n",
    "        'Denotes the total number of samples'\n",
    "        return self.num_time\n",
    "    def get_landmask(self):\n",
    "        land_mass=torch.tensor(np.load('/scratch/cg3306/climate/physical_land_11.npy'),dtype=torch.float32)\n",
    "        land_mass=torch.stack([land_mass],dim=0)\n",
    "        land_mass=torch.stack([land_mass],dim=0)\n",
    "        return land_mass\n",
    "    def __getitem__(self, nt):\n",
    "        'Generates one sample of data'\n",
    "        nt=self.time_downsample[nt]\n",
    "        datsel=self.ds_data.isel(time=[nt])\n",
    "        usurf=datsel.usurf.values\n",
    "        vsurf=datsel.vsurf.values\n",
    "        \n",
    "        x=datsel.xu_ocean.values\n",
    "        y=datsel.yu_ocean.values\n",
    "        dy=np.zeros((len(y),))\n",
    "        dy[1:]=y[1:]-y[:-1]\n",
    "        dy[:-1]=dy[:-1]+dy[1:]\n",
    "        dy[1:-1]=dy[1:-1]/2\n",
    "        dy=(dy-np.mean(dy))/np.std(dy)\n",
    "        cosx=np.cos(x/180*np.pi)\n",
    "        siny=np.sin(y/80*np.pi)\n",
    "        \n",
    "        \n",
    "        usurf=torch.tensor(usurf,dtype=torch.float32)\n",
    "        vsurf=torch.tensor(vsurf,dtype=torch.float32)\n",
    "        \n",
    "        cosx=torch.reshape(torch.tensor(cosx,dtype=torch.float32),[1,1,-1])\n",
    "        siny=torch.reshape(torch.tensor(siny,dtype=torch.float32),[1,-1,1])\n",
    "        dy=torch.reshape(torch.tensor(dy,dtype=torch.float32),[1,-1,1])\n",
    "        fcosx=cosx+siny*0\n",
    "        fsiny=cosx*0+siny\n",
    "        fdy=cosx*0+dy\n",
    "        \n",
    "        \n",
    "        land_mass=torch.tensor(np.load('/scratch/cg3306/climate/physical_land_11.npy'),dtype=torch.float32)\n",
    "        land_mass=torch.stack([land_mass],dim=0)\n",
    "        X=torch.cat([usurf,vsurf,land_mass,fcosx,fsiny,fdy],dim=0)\n",
    "        X[X!=X]=0\n",
    "        X[:1]=X[:1]*(1-X[2:3])\n",
    "        \n",
    "        mx=self.xpad\n",
    "        my=self.ypad\n",
    "        \n",
    "        \n",
    "        sx=datsel.S_x.values\n",
    "        sy=datsel.S_y.values\n",
    "        sx=torch.tensor(sx,dtype=torch.float32)\n",
    "        sy=torch.tensor(sy,dtype=torch.float32)\n",
    "        \n",
    "\n",
    "        Y=torch.cat([sx,sy],dim=0)\n",
    "        \n",
    "        Y[Y!=Y]=0\n",
    "        Y=Y*(1-X[2:3])\n",
    "        \n",
    "        X=torch.cat([X[:,:,-mx:],X,X[:,:,:mx]],dim=2)\n",
    "        X=torch.cat([torch.flip(X[:,:my],[1]),X,torch.flip(X[:,-my:],[1])],dim=1)\n",
    "        \n",
    "        return X,torch.tensor(0),Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215b375a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
